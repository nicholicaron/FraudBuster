{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100",
      "authorship_tag": "ABX9TyMyiatj/QJY4SJgr6lXGRLG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nicholicaron/FraudBuster/blob/main/FraudBuster.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# GNN-Based Real-Time Fraud Detection System (IEEE-CIS Dataset)\n",
        "\n",
        "## Project Overview\n",
        "\n",
        "This project implements a Graph Neural Network (GNN) based system for fraud detection using the IEEE-CIS Fraud Detection dataset. The core idea is to represent transactions and their relationships as a graph, allowing the GNN to learn complex patterns indicative of fraudulent activity that traditional methods might miss. By modeling connections based on shared entities (cards, emails, devices), temporal proximity, and feature similarity, the system aims to identify sophisticated fraud schemes.\n",
        "\n",
        "The project covers:\n",
        "1.  **Data Preprocessing:** Handling missing values, feature engineering, encoding categorical features, and normalizing numerical data from the IEEE-CIS dataset.\n",
        "2.  **Graph Construction:** Transforming tabular transaction data into a heterogeneous graph where transactions are nodes and edges represent various relationships.\n",
        "3.  **GNN Architecture:** Designing a `HeteroGNN` using PyTorch Geometric, capable of processing different types of relationships (edge types).\n",
        "4.  **Model Training & Evaluation:** Training the GNN on labeled data, handling class imbalance, and evaluating performance using fraud-detection-specific metrics (AUCPR, F1-score, Precision, Recall).\n",
        "5.  **Real-Time Considerations (Conceptual):** Discussing the architectural aspects required for deploying such a system in a real-time environment.\n",
        "\n",
        "## Tech Stack & Tools\n",
        "\n",
        "*   **Programming Language:** Python 3.x\n",
        "*   **Core Libraries:**\n",
        "    *   **PyTorch:** For building and training neural networks.\n",
        "    *   **PyTorch Geometric (PyG):** For creating and working with graph neural networks.\n",
        "    *   **Pandas:** For data manipulation and analysis.\n",
        "    *   **NumPy:** For numerical operations.\n",
        "    *   **Scikit-learn:** For preprocessing (scaling, encoding), KNN, and evaluation metrics.\n",
        "*   **Data Visualization:** Matplotlib, Seaborn (for confusion matrix).\n",
        "*   **Dataset:** [IEEE-CIS Fraud Detection Dataset](https://www.kaggle.com/c/ieee-fraud-detection) (requires download from Kaggle).\n",
        "\n",
        "## Key Concepts & System Flow\n",
        "\n",
        "### 1. High-Level System Flow\n",
        "\n",
        "The system processes transactions by first transforming them into a graph structure and then using a GNN to predict fraud.\n",
        "\n",
        "[![](https://mermaid.ink/img/pako:eNqNVW1v2jAQ_iuWp01Mcl-SkACpNAmSvlPala4fBtXkJUdqNTiR43RlVf_7HJuEMCZ1QQJ899xzd8_ZziuOshiwjxNB80d0F845Us9wdkt_oTtBeUEjyTKOQiopCqb3xQPa2_uCRp1xRmP0CV2BSEB7Px-Z2JEGBJ0bAbnIIigKxhOFPAEqSwHomCeMAwhlrUMCHRJ2TnURQcYLKUqdt0IYTFH-XNcoKOMq-IblkComNKstqDY9mJDqiZkA08H4dmMNf8gqZmYSVtWbts460zxl0uQ4uKfpwR0Usi6zes4UrinBqFIFHhvCzulkgq6UommDaQevURWFAQ2FZAulcKFJdAjE2jWVmYBOZ21CDe_nmg94vCPNOV-AAB7BRpvG9P_iXMwmsD38qRRAl0aiy9ZgkQa-tFu81KBxJ1xxumQRMgp_y2MqAR2gaV1qoBjrAdex40qYryWI1b_laEF3fBtNzThY1XdrHI0OOwlNhYtMbDBtjq3xaYv2ns5OBC1jNI2q5AcohIgVqp-H3fGEm25a23aNu9DOncE12_7jR6X-Kq02W1VilFLB5Mr41KIoQliguNqGC5am_ofQ7brWiKgDlD2B_8G1reAwXC_3frFYPvp2_nL0F0E9T8PhOE636zUcvZN-MBy-y7HUOhuGnjPoeq0qnF7ovl9FoQdpGPpDO3Q2DF7XGtnH_2JocaAhudBatInRiAQkJGfkkozrPrf860NJ6unqPrYQu5utaG1HgzmtE5vPxnHO81Ku776CXJdSLcdZwtSZZ9lEUR5to5lkNB2rfFSQoTp-z_qYWOSE8cY-gRc5pisQ18IQ1o1p4xbhGUgQmbpSny0Uqe9RmkVPW4irIrlRvz-O4wTuVjlY5G-LvWOZkGGSCEjUobZI1YTu0kIxSMpSkwMT9VJhMfbVXQ4EL0EsabXEr1X2OZaPsIQ59tXfmIqnOZ7zNxWTU_49y5Z1mMjK5BH7C5oWalXqeyRkVF0iy8aqTk4MIshKLrHvOn1Ngv1X_IJ9Z2DtO06_13M9p9vzXI_gFfYH9r7b9dQ-dyx70O_b_TeCf-ush_sD-9Dtez3X9QaHA_WXYIiZmveVeVHq9-XbH-FbT1k?type=png)](https://mermaid.live/edit#pako:eNqNVW1v2jAQ_iuWp01Mcl-SkACpNAmSvlPala4fBtXkJUdqNTiR43RlVf_7HJuEMCZ1QQJ899xzd8_ZziuOshiwjxNB80d0F845Us9wdkt_oTtBeUEjyTKOQiopCqb3xQPa2_uCRp1xRmP0CV2BSEB7Px-Z2JEGBJ0bAbnIIigKxhOFPAEqSwHomCeMAwhlrUMCHRJ2TnURQcYLKUqdt0IYTFH-XNcoKOMq-IblkComNKstqDY9mJDqiZkA08H4dmMNf8gqZmYSVtWbts460zxl0uQ4uKfpwR0Usi6zes4UrinBqFIFHhvCzulkgq6UommDaQevURWFAQ2FZAulcKFJdAjE2jWVmYBOZ21CDe_nmg94vCPNOV-AAB7BRpvG9P_iXMwmsD38qRRAl0aiy9ZgkQa-tFu81KBxJ1xxumQRMgp_y2MqAR2gaV1qoBjrAdex40qYryWI1b_laEF3fBtNzThY1XdrHI0OOwlNhYtMbDBtjq3xaYv2ns5OBC1jNI2q5AcohIgVqp-H3fGEm25a23aNu9DOncE12_7jR6X-Kq02W1VilFLB5Mr41KIoQliguNqGC5am_ofQ7brWiKgDlD2B_8G1reAwXC_3frFYPvp2_nL0F0E9T8PhOE636zUcvZN-MBy-y7HUOhuGnjPoeq0qnF7ovl9FoQdpGPpDO3Q2DF7XGtnH_2JocaAhudBatInRiAQkJGfkkozrPrf860NJ6unqPrYQu5utaG1HgzmtE5vPxnHO81Ku776CXJdSLcdZwtSZZ9lEUR5to5lkNB2rfFSQoTp-z_qYWOSE8cY-gRc5pisQ18IQ1o1p4xbhGUgQmbpSny0Uqe9RmkVPW4irIrlRvz-O4wTuVjlY5G-LvWOZkGGSCEjUobZI1YTu0kIxSMpSkwMT9VJhMfbVXQ4EL0EsabXEr1X2OZaPsIQ59tXfmIqnOZ7zNxWTU_49y5Z1mMjK5BH7C5oWalXqeyRkVF0iy8aqTk4MIshKLrHvOn1Ngv1X_IJ9Z2DtO06_13M9p9vzXI_gFfYH9r7b9dQ-dyx70O_b_TeCf-ush_sD-9Dtez3X9QaHA_WXYIiZmveVeVHq9-XbH-FbT1k)\n",
        "\n",
        "### 2. Graph Construction Strategy\n",
        "\n",
        "Transactions are represented as nodes. Edges define relationships between them:\n",
        "\n",
        "    Node Type: transaction\n",
        "\n",
        "    Edge Types (Examples):\n",
        "\n",
        "        shared_card_identity: Transactions sharing the same (hashed/combined) card details.\n",
        "\n",
        "        shared_email_P: Transactions with the same payer email domain.\n",
        "\n",
        "        shared_device_info: Transactions originating from the same device fingerprint.\n",
        "\n",
        "        temporal_proximity: Transactions occurring within a short time window of each other.\n",
        "\n",
        "        similar_amount: Transactions with numerically similar transaction amounts (identified via k-NN).\n",
        "\n",
        "[![](https://mermaid.ink/img/pako:eNpdklFP6yAUx78KOcZEE7a0QNeNJb64-KQ3N9qne2saUthKbKGhTDeXfXfZaucmTxz-v_M_Bzg7KK1UwGHlRFuhx-fcoLCy-P9N5oTpROm1NSi-ff0WyKVATgK9FOhJYJcCOwnJpZAchKE8Go1QVwmnZFEKJwstlfHab8P5XWhifs551bTWibpond3o5kTRgSJnblK961IV2ixtT7GBokcq5NfCFaKxa-N7IhkIduajGqHr4m9PxPOh8-tr9OK3tTYrZMLDdv1pWYuuW6gl8j_3_RNktNR1za_uF-kDJbjzzr4pfkUp_d6PPrT0FSftZn5mFOrhjOCM4ozhLPltOgccflNL4N6tFYZGudBrCGF3MMnBV6pROfCwlcK95ZCbfchphflnbTOkObteVcCXou5CtG6l8GqhRZiTH0QZqdz94aWAT48OwHewAT6ZjQkhNKWzCWERoQzDFjiLxjQmbDJjU8JIPE2TPYbPY81oHKIoLEqnJKFplGJQUnvrnvr5PI7p_guKUtJh?type=png)](https://mermaid.live/edit#pako:eNpdklFP6yAUx78KOcZEE7a0QNeNJb64-KQ3N9qne2saUthKbKGhTDeXfXfZaucmTxz-v_M_Bzg7KK1UwGHlRFuhx-fcoLCy-P9N5oTpROm1NSi-ff0WyKVATgK9FOhJYJcCOwnJpZAchKE8Go1QVwmnZFEKJwstlfHab8P5XWhifs551bTWibpond3o5kTRgSJnblK961IV2ixtT7GBokcq5NfCFaKxa-N7IhkIduajGqHr4m9PxPOh8-tr9OK3tTYrZMLDdv1pWYuuW6gl8j_3_RNktNR1za_uF-kDJbjzzr4pfkUp_d6PPrT0FSftZn5mFOrhjOCM4ozhLPltOgccflNL4N6tFYZGudBrCGF3MMnBV6pROfCwlcK95ZCbfchphflnbTOkObteVcCXou5CtG6l8GqhRZiTH0QZqdz94aWAT48OwHewAT6ZjQkhNKWzCWERoQzDFjiLxjQmbDJjU8JIPE2TPYbPY81oHKIoLEqnJKFplGJQUnvrnvr5PI7p_guKUtJh)\n",
        "\n",
        "### 3. GNN Architecture (HeteroGNN)\n",
        "\n",
        "A Heterogeneous GNN (HeteroConv in PyG) is used to process the graph with multiple edge types. Each edge type can have its own message passing mechanism (e.g., using SAGEConv or GATConv). The information from different relationship types is then aggregated.\n",
        "\n",
        "[![](https://mermaid.ink/img/pako:eNqVVm2P2jgQ_isjV5VaXUAkEF6CVKldur1KW1pd0X24ZbXyJiZYJHZkO3twiP_eySsO3KraiA8z5plnhvEzE44klBEjAYkVzbawWqwF4PNVZLm5ZdTkiun7JUKg8aAHK0WFpqHhUugH6PU-IJ4bTpM7LhhV72oPKhfu6IEp-AM-YsQzLaLez9eiSqTzpyrzl-WyxGm4R7OK0Q8VqHgirliZEVafzqclzP0q7r_nBiuGjZJpt5iqvj-ZYUreSPHsHo9npy7NPZ3agjpFWWGPC2YoT7C82gjgkse1yu2WfPdX95uioWWL3aq3n9MnFkVcxHU7v-n4B9X68XMUs9UhY-49nkBxhBi8gPY8ANaP-w7oLVUsegypih7mL-X6X2rvBWqvoTYszaSiySt5ly_wLgPo9_uXZFc_uOT8GMeKxdQw99iY2M3Tb2K9i9jfwJcvw5mIzs7ZevsW_uY6p0lygISLnS0TeEpkuAMjgRsNUSWVTuhqyzXgJ5WKQShFyDKDXEB1LZhCfr1WgkWCooMhFfDEwCge7g4dQjv7hdYb0c6hzsv2WcJDbqq6Ux5vDTLnmmFFOmfaAbkxTABPEccieygu05yn2X13tnHMF0pmMjfvrUZa2DJ2yfamHJnvqhrcI2oCbnNltjiO5_kHqaCebAQ0F99eS7OrrHEv6ZutMK8RV-lK1C0X7cYq7c6-asq3UGVURXAnY7zfZutUHor8VtE8gp8hXu1Du1Hwin6aAzY8rvwwQfkt2Aa4LId_w5MkeDOYDJk7drRRcseCN8PhsLZ7__LIbAMv288v4jMlQ6Z1tcMqFgy7cV9Fggp8_lRqtmJICk3gLDDxKppK6TbRYORNWwrf97sUbrZvDiJabC9FDwH44Jdts8i7ryLHbn_dwHkXbYnBsXTnWBfpXAvC7mWH0JZ926sO4mp3OVcb6epk6ZwXjmNtUquNc-LgS5lHJDAqZw5JmUpp4ZJjkX1NcFZStiYBmhFVuzVZixPGZFT8I2XahCmZx1sSbGii0cuzCFMuOMXlkranCieKqRuZC0MCz_dKEhIcyZ4Es0l_NB4Nx8PBbOqORv7QIQcSDCd9f-aNp_54NhuNvens5JD_yqyD_nQymuEz9GYTbzBwJw5hETdSfav-aJT_N06_AKcNwds?type=png)](https://mermaid.live/edit#pako:eNqVVm2P2jgQ_isjV5VaXUAkEF6CVKldur1KW1pd0X24ZbXyJiZYJHZkO3twiP_eySsO3KraiA8z5plnhvEzE44klBEjAYkVzbawWqwF4PNVZLm5ZdTkiun7JUKg8aAHK0WFpqHhUugH6PU-IJ4bTpM7LhhV72oPKhfu6IEp-AM-YsQzLaLez9eiSqTzpyrzl-WyxGm4R7OK0Q8VqHgirliZEVafzqclzP0q7r_nBiuGjZJpt5iqvj-ZYUreSPHsHo9npy7NPZ3agjpFWWGPC2YoT7C82gjgkse1yu2WfPdX95uioWWL3aq3n9MnFkVcxHU7v-n4B9X68XMUs9UhY-49nkBxhBi8gPY8ANaP-w7oLVUsegypih7mL-X6X2rvBWqvoTYszaSiySt5ly_wLgPo9_uXZFc_uOT8GMeKxdQw99iY2M3Tb2K9i9jfwJcvw5mIzs7ZevsW_uY6p0lygISLnS0TeEpkuAMjgRsNUSWVTuhqyzXgJ5WKQShFyDKDXEB1LZhCfr1WgkWCooMhFfDEwCge7g4dQjv7hdYb0c6hzsv2WcJDbqq6Ux5vDTLnmmFFOmfaAbkxTABPEccieygu05yn2X13tnHMF0pmMjfvrUZa2DJ2yfamHJnvqhrcI2oCbnNltjiO5_kHqaCebAQ0F99eS7OrrHEv6ZutMK8RV-lK1C0X7cYq7c6-asq3UGVURXAnY7zfZutUHor8VtE8gp8hXu1Du1Hwin6aAzY8rvwwQfkt2Aa4LId_w5MkeDOYDJk7drRRcseCN8PhsLZ7__LIbAMv288v4jMlQ6Z1tcMqFgy7cV9Fggp8_lRqtmJICk3gLDDxKppK6TbRYORNWwrf97sUbrZvDiJabC9FDwH44Jdts8i7ryLHbn_dwHkXbYnBsXTnWBfpXAvC7mWH0JZ926sO4mp3OVcb6epk6ZwXjmNtUquNc-LgS5lHJDAqZw5JmUpp4ZJjkX1NcFZStiYBmhFVuzVZixPGZFT8I2XahCmZx1sSbGii0cuzCFMuOMXlkranCieKqRuZC0MCz_dKEhIcyZ4Es0l_NB4Nx8PBbOqORv7QIQcSDCd9f-aNp_54NhuNvens5JD_yqyD_nQymuEz9GYTbzBwJw5hETdSfav-aJT_N06_AKcNwds)\n",
        "\n",
        "## Future Enhancements & Considerations\n",
        "\n",
        "1. **Scalability**: For larger datasets, use Approximate Nearest Neighbors (ANN) libraries (e.g., FAISS) for similarity edge creation. Explore distributed GNN training frameworks.\n",
        "\n",
        "2. **Dynamic Graph Handling**: Integrate with graph databases (Neo4j, TigerGraph) for efficient storage, querying, and updates in a real-time production environment.\n",
        "\n",
        "3. **Advanced Feature Engineering**: Incorporate graph-native features like node centrality, clustering coefficients, or motif counts.\n",
        "\n",
        "4. **Interpretability**: Explore advanced GNN explanation techniques suitable for heterogeneous graphs to understand model decisions.\n",
        "\n",
        "5. **Hyperparameter Optimization**: Use tools like Optuna or Ray Tune for systematic hyperparameter tuning.\n",
        "\n",
        "6. **Production Deployment**: Package the model and inference logic for serving using frameworks like TorchServe, Triton Inference Server, or custom FastAPI endpoints."
      ],
      "metadata": {
        "id": "JlsHe8XnUk4l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc --version"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5d_NBP1FS7-H",
        "outputId": "f294aa13-f9f7-42d2-ad2e-3f77ae2e3e84"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2024 NVIDIA Corporation\n",
            "Built on Thu_Jun__6_02:18:23_PDT_2024\n",
            "Cuda compilation tools, release 12.5, V12.5.82\n",
            "Build cuda_12.5.r12.5/compiler.34385749_0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "print(torch.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bOJ9AnVASttE",
        "outputId": "c017d793-39da-4c03-cb36-a60c4565cc5a"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.6.0+cu124\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "CNQT7vxqQLvp",
        "outputId": "edde8815-edac-4d26-8e94-7bd192565734"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PyTorch version: 2.6.0\n",
            "CUDA version for PyG wheels: cu124\n",
            "Looking in links: https://data.pyg.org/whl/torch-2.6.0+cu124.html\n",
            "Collecting pyg_lib\n",
            "  Downloading https://data.pyg.org/whl/torch-2.6.0%2Bcu124/pyg_lib-0.4.0%2Bpt26cu124-cp311-cp311-linux_x86_64.whl (4.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.7/4.7 MB\u001b[0m \u001b[31m38.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torch_scatter\n",
            "  Downloading https://data.pyg.org/whl/torch-2.6.0%2Bcu124/torch_scatter-2.1.2%2Bpt26cu124-cp311-cp311-linux_x86_64.whl (10.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.8/10.8 MB\u001b[0m \u001b[31m99.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torch_sparse\n",
            "  Downloading https://data.pyg.org/whl/torch-2.6.0%2Bcu124/torch_sparse-0.6.18%2Bpt26cu124-cp311-cp311-linux_x86_64.whl (5.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.0/5.0 MB\u001b[0m \u001b[31m89.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torch_cluster\n",
            "  Downloading https://data.pyg.org/whl/torch-2.6.0%2Bcu124/torch_cluster-1.6.3%2Bpt26cu124-cp311-cp311-linux_x86_64.whl (3.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m92.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from torch_sparse) (1.15.3)\n",
            "Requirement already satisfied: numpy<2.5,>=1.23.5 in /usr/local/lib/python3.11/dist-packages (from scipy->torch_sparse) (2.0.2)\n",
            "Installing collected packages: torch_scatter, pyg_lib, torch_sparse, torch_cluster\n",
            "Successfully installed pyg_lib-0.4.0+pt26cu124 torch_cluster-1.6.3+pt26cu124 torch_scatter-2.1.2+pt26cu124 torch_sparse-0.6.18+pt26cu124\n",
            "pyg_lib installed successfully.\n",
            "torch_sparse installed successfully.\n",
            "Collecting torch_geometric\n",
            "  Downloading torch_geometric-2.6.1-py3-none-any.whl.metadata (63 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.1/63.1 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (3.11.15)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (2025.3.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (3.1.6)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (2.0.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (5.9.5)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (3.2.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (4.67.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (6.4.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (1.20.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch_geometric) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->torch_geometric) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->torch_geometric) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->torch_geometric) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->torch_geometric) (2025.4.26)\n",
            "Downloading torch_geometric-2.6.1-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m20.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: torch_geometric\n",
            "Successfully installed torch_geometric-2.6.1\n",
            "Collecting faiss-gpu-cu12\n",
            "  Downloading faiss_gpu_cu12-1.11.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
            "Collecting numpy<2 (from faiss-gpu-cu12)\n",
            "  Downloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from faiss-gpu-cu12) (24.2)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12>=12.1.105 in /usr/local/lib/python3.11/dist-packages (from faiss-gpu-cu12) (12.5.82)\n",
            "Requirement already satisfied: nvidia-cublas-cu12>=12.1.3.1 in /usr/local/lib/python3.11/dist-packages (from faiss-gpu-cu12) (12.5.3.2)\n",
            "Downloading faiss_gpu_cu12-1.11.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (48.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.0/48.0 MB\u001b[0m \u001b[31m32.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m55.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: numpy, faiss-gpu-cu12\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.0.2\n",
            "    Uninstalling numpy-2.0.2:\n",
            "      Successfully uninstalled numpy-2.0.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed faiss-gpu-cu12-1.11.0 numpy-1.26.4\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "# Determine PyTorch and CUDA versions\n",
        "TORCH_VERSION = torch.__version__.split('+')[0] # e.g., \"2.1.0\"\n",
        "CUDA_VERSION = \"\"\n",
        "if torch.cuda.is_available():\n",
        "    # Format CUDA version for PyG wheels (e.g., \"cu118\", \"cu121\")\n",
        "    # torch.version.cuda might be \"11.8\", \"12.1\", etc.\n",
        "    cuda_v_major_minor = torch.version.cuda.split('.')\n",
        "    CUDA_VERSION = f\"cu{cuda_v_major_minor[0]}{cuda_v_major_minor[1]}\"\n",
        "else:\n",
        "    CUDA_VERSION = \"cpu\"\n",
        "\n",
        "print(f\"PyTorch version: {TORCH_VERSION}\")\n",
        "print(f\"CUDA version for PyG wheels: {CUDA_VERSION}\")\n",
        "\n",
        "# Install PyG's core compiled libraries\n",
        "# Note: These have to be compatible with torch_geometric version,\n",
        "# This command usually gets the latest compatible.\n",
        "!pip install pyg_lib torch_scatter torch_sparse torch_cluster -f https://data.pyg.org/whl/torch-{TORCH_VERSION}+{CUDA_VERSION}.html\n",
        "\n",
        "# Verify (optional, but good practice)\n",
        "try:\n",
        "    import pyg_lib\n",
        "    print(\"pyg_lib installed successfully.\")\n",
        "except ImportError:\n",
        "    print(\"pyg_lib installation failed or not found.\")\n",
        "try:\n",
        "    import torch_sparse\n",
        "    print(\"torch_sparse installed successfully.\")\n",
        "except ImportError:\n",
        "    print(\"torch_sparse installation failed or not found.\")\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "!pip install torch_geometric\n",
        "from torch_geometric.data import Data, HeteroData\n",
        "from torch_geometric.nn import SAGEConv, HeteroConv, Linear # Using SAGEConv for its efficiency\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "!pip install faiss-gpu-cu12\n",
        "import faiss # For feature similarity edges\n",
        "from torch_geometric.loader import NeighborLoader # For mini-batching\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score, average_precision_score, confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import time\n",
        "import pickle\n",
        "import os\n",
        "\n",
        "# --- Constants ---\n",
        "DATA_PATH = './'  # Path to IEEE-CIS dataset files\n",
        "TRANSACTION_FILE = 'train_transaction.csv'\n",
        "IDENTITY_FILE = 'train_identity.csv'\n",
        "TARGET = 'isFraud'\n",
        "TRANSACTION_ID = 'TransactionID'\n",
        "TRANSACTION_DT = 'TransactionDT'\n",
        "SEED = 42\n",
        "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Set seeds for reproducibility\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed_all(SEED) # For multi-GPU\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "\n",
        "# --- Helper Functions ---\n",
        "def save_object(obj, filename):\n",
        "    \"\"\"Saves an object to a file using pickle.\"\"\"\n",
        "    os.makedirs(os.path.dirname(filename), exist_ok=True)\n",
        "    with open(filename, 'wb') as f:\n",
        "        pickle.dump(obj, f)\n",
        "\n",
        "def load_object(filename):\n",
        "    \"\"\"Loads an object from a file using pickle.\"\"\"\n",
        "    with open(filename, 'rb') as f:\n",
        "        return pickle.load(f)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Phase 1: Dataset Understanding and Preprocessing ---\n",
        "print(\"--- Phase 1: Data Preprocessing ---\")\n",
        "\n",
        "def load_and_merge_data(transaction_file, identity_file, data_path, sample_nrows=None):\n",
        "    print(f\"Loading data... (sample_nrows={sample_nrows or 'all'})\")\n",
        "    try:\n",
        "        df_transaction = pd.read_csv(os.path.join(data_path, transaction_file), nrows=sample_nrows)\n",
        "        df_identity = pd.read_csv(os.path.join(data_path, identity_file), nrows=sample_nrows)\n",
        "    except FileNotFoundError as e:\n",
        "        print(f\"ERROR: Dataset files not found. {e}\")\n",
        "        print(\"Please download the IEEE-CIS Fraud Detection dataset from Kaggle and place it in the DATA_PATH.\")\n",
        "        exit()\n",
        "    print(f\"Transaction data shape: {df_transaction.shape}\")\n",
        "    print(f\"Identity data shape: {df_identity.shape}\")\n",
        "    df_merged = pd.merge(df_transaction, df_identity, on=TRANSACTION_ID, how='left')\n",
        "    print(f\"Merged data shape: {df_merged.shape}\")\n",
        "    del df_transaction, df_identity\n",
        "    return df_merged\n",
        "\n",
        "def select_and_engineer_features(df):\n",
        "    print(\"Selecting and engineering features...\")\n",
        "    numerical_cols_initial = ['TransactionAmt', 'dist1', 'dist2'] + \\\n",
        "                             [f'C{i}' for i in range(1, 15)] + \\\n",
        "                             [f'D{i}' for i in range(1, 16)] + \\\n",
        "                             [f'V{i}' for i in [12, 13, 35, 36, 44, 45, 53, 54, 61, 62, 75, 76, 82, 83, 95, 96, 97,\n",
        "                                                257, 258, 261, 264, 265, 266, 267, 268, 270, 271, 272]]\n",
        "    categorical_cols_initial = ['ProductCD', 'P_emaildomain', 'R_emaildomain'] + \\\n",
        "                               [f'card{i}' for i in range(1, 7)] + \\\n",
        "                               [f'addr1', 'addr2'] + \\\n",
        "                               [f'M{i}' for i in range(1, 10)] + \\\n",
        "                               ['DeviceType', 'DeviceInfo'] + \\\n",
        "                               [f'id_{str(i).zfill(2)}' for i in range(12, 39)]\n",
        "    existing_numerical_cols = [col for col in numerical_cols_initial if col in df.columns]\n",
        "    existing_categorical_cols = [col for col in categorical_cols_initial if col in df.columns]\n",
        "    core_cols = [TRANSACTION_ID, TARGET]\n",
        "    if TRANSACTION_DT in df.columns:\n",
        "        core_cols.append(TRANSACTION_DT)\n",
        "    else:\n",
        "        print(f\"Warning: '{TRANSACTION_DT}' column not found. Temporal features cannot be engineered.\")\n",
        "\n",
        "    card_cols_for_key = [f'card{i}' for i in range(1,7) if f'card{i}' in existing_categorical_cols]\n",
        "    if card_cols_for_key:\n",
        "        df['card_identity_key'] = df[card_cols_for_key].fillna('MISSING_CARD_PART').astype(str).agg('_'.join, axis=1)\n",
        "        if 'card_identity_key' not in existing_categorical_cols:\n",
        "             existing_categorical_cols.append('card_identity_key')\n",
        "    else:\n",
        "        df['card_identity_key'] = \"NO_CARD_INFO\"\n",
        "        if 'card_identity_key' not in existing_categorical_cols:\n",
        "             existing_categorical_cols.append('card_identity_key')\n",
        "\n",
        "    if TRANSACTION_DT in df.columns:\n",
        "        df['HourOfDay'] = (df[TRANSACTION_DT] // 3600) % 24\n",
        "        if 'HourOfDay' not in existing_numerical_cols: existing_numerical_cols.append('HourOfDay')\n",
        "        df['DayOfWeek'] = (df[TRANSACTION_DT] // (3600 * 24)) % 7\n",
        "        if 'DayOfWeek' not in existing_numerical_cols: existing_numerical_cols.append('DayOfWeek')\n",
        "        df['IsWeekend'] = df['DayOfWeek'].apply(lambda x: 1 if x >= 5 else 0)\n",
        "        if 'IsWeekend' not in existing_numerical_cols: existing_numerical_cols.append('IsWeekend')\n",
        "\n",
        "    selected_cols = core_cols + existing_numerical_cols + existing_categorical_cols\n",
        "    selected_cols = sorted(list(set(col for col in selected_cols if col in df.columns)))\n",
        "    df_processed = df[selected_cols].copy()\n",
        "    print(f\"Selected {len(existing_numerical_cols)} numerical and {len(existing_categorical_cols)} categorical features.\")\n",
        "    return df_processed, existing_numerical_cols, existing_categorical_cols\n",
        "\n",
        "def preprocess_data(df, numerical_cols, categorical_cols):\n",
        "    print(\"Preprocessing: Handling missing values, encoding, and scaling...\")\n",
        "    all_numerical_features_for_scaling = list(numerical_cols)\n",
        "    for col in numerical_cols:\n",
        "        if df[col].isnull().any():\n",
        "            indicator_col_name = col + '_isnull'\n",
        "            df[indicator_col_name] = df[col].isnull().astype(int)\n",
        "            if indicator_col_name not in all_numerical_features_for_scaling:\n",
        "                all_numerical_features_for_scaling.append(indicator_col_name)\n",
        "            df[col] = df[col].fillna(df[col].median())\n",
        "    for col in categorical_cols:\n",
        "        if df[col].isnull().any():\n",
        "            df[col] = df[col].astype(str).fillna('__MISSING__')\n",
        "        df[col] = df[col].astype(str)\n",
        "    label_encoders = {}\n",
        "    for col in categorical_cols:\n",
        "        le = LabelEncoder()\n",
        "        df[col] = le.fit_transform(df[col])\n",
        "        label_encoders[col] = le\n",
        "    scaler = StandardScaler()\n",
        "    cols_to_scale_existing = [col for col in all_numerical_features_for_scaling if col in df.columns]\n",
        "    if cols_to_scale_existing:\n",
        "        df[cols_to_scale_existing] = scaler.fit_transform(df[cols_to_scale_existing])\n",
        "    if TRANSACTION_DT in df.columns:\n",
        "        df = df.sort_values(TRANSACTION_DT).reset_index(drop=True)\n",
        "    print(\"Preprocessing done.\")\n",
        "    return df, label_encoders, scaler, cols_to_scale_existing\n",
        "\n",
        "# --- Main Preprocessing Execution ---\n",
        "raw_df = load_and_merge_data(TRANSACTION_FILE, IDENTITY_FILE, DATA_PATH)\n",
        "if raw_df.empty: exit()\n",
        "df_for_features = raw_df.copy()\n",
        "del raw_df\n",
        "df_featured, base_numerical_cols, base_categorical_cols = select_and_engineer_features(df_for_features)\n",
        "# Store original df_featured for potential use in real-time simulation's `preprocess_new_transaction` for stats\n",
        "# df_featured_for_stats = df_featured.copy() # If needed for global median/mode from train set\n",
        "del df_for_features\n",
        "df_processed, fitted_label_encoders, fitted_scaler, final_numerical_feature_names = preprocess_data(\n",
        "    df_featured, base_numerical_cols, base_categorical_cols\n",
        ")\n",
        "# Save preprocessors\n",
        "# Make sure 'preprocessors' directory exists if you uncomment saving\n",
        "# os.makedirs(os.path.join(DATA_PATH, 'preprocessors'), exist_ok=True)\n",
        "# save_object(fitted_label_encoders, os.path.join(DATA_PATH, 'preprocessors', 'label_encoders.pkl'))\n",
        "# save_object(fitted_scaler, os.path.join(DATA_PATH, 'preprocessors', 'scaler.pkl'))\n",
        "\n",
        "node_feature_column_names = final_numerical_feature_names + base_categorical_cols\n",
        "node_feature_column_names = sorted(list(set(col for col in node_feature_column_names if col in df_processed.columns)))\n",
        "if not node_feature_column_names: print(\"CRITICAL ERROR: No node feature columns.\"); exit()\n",
        "if TARGET not in df_processed.columns: print(f\"CRITICAL ERROR: Target column '{TARGET}' not found.\"); exit()\n",
        "\n",
        "node_features_tensor = torch.tensor(df_processed[node_feature_column_names].values, dtype=torch.float)\n",
        "labels_tensor = torch.tensor(df_processed[TARGET].values, dtype=torch.float).unsqueeze(1)\n",
        "num_nodes = len(df_processed)\n",
        "num_node_features = node_features_tensor.shape[1]\n",
        "\n",
        "print(f\"\\n--- Preprocessing Summary ---\")\n",
        "print(f\"Number of nodes: {num_nodes}, Features per node: {num_node_features}\")\n",
        "print(f\"Target distribution:\\n{df_processed[TARGET].value_counts(normalize=True)}\")\n",
        "if df_processed[TARGET].nunique() < 2: print(\"Warning: Target column has < 2 unique values.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VCuj_AXFUE8x",
        "outputId": "f2507549-43ff-4ca0-8b0b-9f4803704e07"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Phase 1: Data Preprocessing ---\n",
            "Loading data... (sample_nrows=all)\n",
            "Transaction data shape: (458923, 394)\n",
            "Identity data shape: (144233, 41)\n",
            "Merged data shape: (458923, 434)\n",
            "Selecting and engineering features...\n",
            "Selected 63 numerical and 50 categorical features.\n",
            "Preprocessing: Handling missing values, encoding, and scaling...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-4-39728d37829c>:71: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[indicator_col_name] = df[col].isnull().astype(int)\n",
            "<ipython-input-4-39728d37829c>:71: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[indicator_col_name] = df[col].isnull().astype(int)\n",
            "<ipython-input-4-39728d37829c>:71: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[indicator_col_name] = df[col].isnull().astype(int)\n",
            "<ipython-input-4-39728d37829c>:71: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[indicator_col_name] = df[col].isnull().astype(int)\n",
            "<ipython-input-4-39728d37829c>:71: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[indicator_col_name] = df[col].isnull().astype(int)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Preprocessing done.\n",
            "\n",
            "--- Preprocessing Summary ---\n",
            "Number of nodes: 458923, Features per node: 164\n",
            "Target distribution:\n",
            "isFraud\n",
            "0    0.964744\n",
            "1    0.035256\n",
            "Name: proportion, dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Phase 2: Graph Construction ---\n",
        "print(\"\\n--- Phase 2: Graph Construction ---\")\n",
        "# The global 'fitted_label_encoders' will be used inside build_graph\n",
        "label_encoders_for_graph = fitted_label_encoders # Make it explicitly available\n",
        "\n",
        "def build_graph(df_processed_ref, node_features_tensor_ref, labels_tensor_ref, num_nodes_ref, seed_ref):\n",
        "    graph = HeteroData()\n",
        "    graph['transaction'].x = node_features_tensor_ref\n",
        "    graph['transaction'].y = labels_tensor_ref\n",
        "    graph['transaction'].num_nodes = num_nodes_ref\n",
        "    tx_id_to_node_idx = {tx_id: i for i, tx_id in enumerate(df_processed_ref[TRANSACTION_ID])}\n",
        "    created_edge_types_for_model = []\n",
        "\n",
        "    def add_edges_by_exact_match(data_graph, df_ref, group_by_col_name, edge_type_name_base, node_id_map):\n",
        "        print(f\"Creating '{edge_type_name_base}' edges for '{group_by_col_name}'...\")\n",
        "        edge_list_src, edge_list_dst = [], []\n",
        "        df_to_group = df_ref\n",
        "        if group_by_col_name in label_encoders_for_graph: # Use passed label_encoders\n",
        "            le_for_col = label_encoders_for_graph[group_by_col_name]\n",
        "            try:\n",
        "                missing_val_enc = le_for_col.transform(['__MISSING__'])[0]\n",
        "                # Only group by non-missing values for these types of edges\n",
        "                df_to_group = df_ref[df_ref[group_by_col_name] != missing_val_enc]\n",
        "            except ValueError: pass # '__MISSING__' not in this encoder's classes or column has no missing post-fillna\n",
        "\n",
        "        grouped = df_to_group.groupby(group_by_col_name)\n",
        "        for _, group_df in grouped:\n",
        "            # Note: Reduced max group size for edges\n",
        "            if 1 < len(group_df) < 50: # Heuristic to avoid super-nodes, more conservative\n",
        "                node_indices = [node_id_map[tx_id] for tx_id in group_df[TRANSACTION_ID] if tx_id in node_id_map]\n",
        "                for i in range(len(node_indices)):\n",
        "                    for j in range(i + 1, len(node_indices)):\n",
        "                        edge_list_src.append(node_indices[i])\n",
        "                        edge_list_dst.append(node_indices[j])\n",
        "        if edge_list_src:\n",
        "            src = torch.tensor(edge_list_src, dtype=torch.long)\n",
        "            dst = torch.tensor(edge_list_dst, dtype=torch.long)\n",
        "            data_graph['transaction', edge_type_name_base, 'transaction'].edge_index = torch.stack([src, dst], dim=0)\n",
        "            data_graph['transaction', f'rev_{edge_type_name_base}', 'transaction'].edge_index = torch.stack([dst, src], dim=0)\n",
        "            created_edge_types_for_model.extend([\n",
        "                ('transaction', edge_type_name_base, 'transaction'),\n",
        "                ('transaction', f'rev_{edge_type_name_base}', 'transaction')\n",
        "            ])\n",
        "            print(f\"    Added {len(edge_list_src)} '{edge_type_name_base}' (and reverse) edges.\")\n",
        "        else: print(f\"    No '{edge_type_name_base}' edges created for '{group_by_col_name}'.\")\n",
        "\n",
        "    if 'card_identity_key' in df_processed_ref.columns:\n",
        "        add_edges_by_exact_match(graph, df_processed_ref, 'card_identity_key', 'shared_card_identity', tx_id_to_node_idx)\n",
        "    if 'P_emaildomain' in df_processed_ref.columns:\n",
        "         add_edges_by_exact_match(graph, df_processed_ref, 'P_emaildomain', 'shared_email_P', tx_id_to_node_idx)\n",
        "    if 'DeviceInfo' in df_processed_ref.columns:\n",
        "        add_edges_by_exact_match(graph, df_processed_ref, 'DeviceInfo', 'shared_device_info', tx_id_to_node_idx)\n",
        "\n",
        "    if TRANSACTION_DT in df_processed_ref.columns:\n",
        "        print(\"Creating 'temporal_proximity' edges...\")\n",
        "        temporal_edges_src, temporal_edges_dst = [], []\n",
        "        time_window_seconds = 600\n",
        "        timestamps = df_processed_ref[TRANSACTION_DT].values\n",
        "        node_indices = df_processed_ref.index.values # Assumes index is 0 to N-1\n",
        "        for i in range(len(node_indices)):\n",
        "            current_time = timestamps[i]\n",
        "            # Iterate forwards to find subsequent transactions in window\n",
        "            for j in range(i + 1, len(node_indices)):\n",
        "                if (timestamps[j] - current_time) <= time_window_seconds:\n",
        "                    temporal_edges_src.append(node_indices[i])\n",
        "                    temporal_edges_dst.append(node_indices[j])\n",
        "                else: # Since data is sorted by time, we can break early\n",
        "                    break\n",
        "        if temporal_edges_src:\n",
        "            src = torch.tensor(temporal_edges_src, dtype=torch.long)\n",
        "            dst = torch.tensor(temporal_edges_dst, dtype=torch.long)\n",
        "            graph['transaction', 'temporal_proximity', 'transaction'].edge_index = torch.stack([src, dst], dim=0)\n",
        "            graph['transaction', 'rev_temporal_proximity', 'transaction'].edge_index = torch.stack([dst, src], dim=0)\n",
        "            created_edge_types_for_model.extend([\n",
        "                ('transaction', 'temporal_proximity', 'transaction'),\n",
        "                ('transaction', 'rev_temporal_proximity', 'transaction')\n",
        "            ])\n",
        "            print(f\"    Added {len(temporal_edges_src)} 'temporal_proximity' (and reverse) edges.\")\n",
        "        else:\n",
        "            print(\"    No 'temporal_proximity' edges created.\")\n",
        "\n",
        "\n",
        "    if faiss and 'TransactionAmt' in df_processed_ref.columns and pd.api.types.is_numeric_dtype(df_processed_ref['TransactionAmt']):\n",
        "        print(\"\\nCreating 'similar_amount' edges using FAISS ANN...\")\n",
        "        # Ensure features are C-contiguous\n",
        "        sim_features_np = np.ascontiguousarray(df_processed_ref[['TransactionAmt']].values.astype(np.float32))\n",
        "        n_total, feat_dim = sim_features_np.shape[0], sim_features_np.shape[1]\n",
        "        n_neighbors = 4 # Note: k+1, so k=3 nearest neighbors\n",
        "        if n_total >= n_neighbors and feat_dim > 0:\n",
        "            sim_amt_src, sim_amt_dst = [], []\n",
        "            try:\n",
        "                index = faiss.IndexFlatL2(feat_dim)\n",
        "                index.add(sim_features_np)\n",
        "                D, I = index.search(sim_features_np, n_neighbors)\n",
        "                all_original_indices = df_processed_ref.index.values\n",
        "                for i_row in range(n_total):\n",
        "                    # Start from 1 to exclude self-loops from KNN\n",
        "                    for j_neighbor_idx_in_row in range(1, n_neighbors):\n",
        "                        neighbor_node_original_idx = all_original_indices[I[i_row, j_neighbor_idx_in_row]]\n",
        "                        # Ensure we don't add self-loops if original indices could be the same by chance (unlikely with unique indices)\n",
        "                        if all_original_indices[i_row] != neighbor_node_original_idx :\n",
        "                            sim_amt_src.append(all_original_indices[i_row])\n",
        "                            sim_amt_dst.append(neighbor_node_original_idx)\n",
        "                if sim_amt_src:\n",
        "                    src = torch.tensor(sim_amt_src, dtype=torch.long)\n",
        "                    dst = torch.tensor(sim_amt_dst, dtype=torch.long)\n",
        "                    graph['transaction', 'similar_amount', 'transaction'].edge_index = torch.stack([src, dst], dim=0)\n",
        "                    graph['transaction', 'rev_similar_amount', 'transaction'].edge_index = torch.stack([dst, src], dim=0) # Add reverse edges\n",
        "                    created_edge_types_for_model.extend([\n",
        "                        ('transaction', 'similar_amount', 'transaction'),\n",
        "                        ('transaction', 'rev_similar_amount', 'transaction')\n",
        "                    ])\n",
        "                    print(f\"    Added {len(sim_amt_src)} 'similar_amount' (and reverse) edges via FAISS.\")\n",
        "                else:\n",
        "                    print(\"    No 'similar_amount' edges created (empty src/dst list).\")\n",
        "            except Exception as e: print(f\"    FAISS Error: {e}.\")\n",
        "        else: print(\"    Skipping 'similar_amount' edges: Not enough samples or feature dim is 0 for FAISS.\")\n",
        "\n",
        "    all_potential_edge_types_meta = [\n",
        "        ('transaction', et, 'transaction') for et_base in ['shared_card_identity', 'shared_email_P', 'shared_device_info', 'temporal_proximity', 'similar_amount'] for et in [et_base, f'rev_{et_base}']\n",
        "    ]\n",
        "    for src_type, edge_type, dst_type in all_potential_edge_types_meta:\n",
        "        if (src_type, edge_type, dst_type) not in graph.edge_types:\n",
        "            graph[src_type, edge_type, dst_type].edge_index = torch.empty((2, 0), dtype=torch.long)\n",
        "\n",
        "    final_model_edge_types = [et for et in created_edge_types_for_model if graph[et].num_edges > 0]\n",
        "    if not final_model_edge_types:\n",
        "        print(\"WARNING: No edges created. Adding self-loops.\")\n",
        "        idx = torch.arange(graph['transaction'].num_nodes, dtype=torch.long)\n",
        "        graph['transaction', 'self_loop', 'transaction'].edge_index = torch.stack([idx, idx], dim=0)\n",
        "        final_model_edge_types.append(('transaction', 'self_loop', 'transaction'))\n",
        "\n",
        "    print(\"\\nGraph construction summary:\"); print(graph)\n",
        "    print(f\"Edge types for HeteroConv: {final_model_edge_types}\")\n",
        "    return graph, final_model_edge_types\n",
        "\n",
        "# Call graph construction\n",
        "graph_data_obj, model_edge_types = build_graph(df_processed, node_features_tensor, labels_tensor, num_nodes, SEED)\n",
        "\n",
        "# Data splitting (Time-based)\n",
        "train_ratio, val_ratio = 0.7, 0.15\n",
        "n_train = int(num_nodes * train_ratio)\n",
        "n_val = int(num_nodes * val_ratio)\n",
        "train_mask = torch.zeros(num_nodes, dtype=torch.bool)\n",
        "val_mask = torch.zeros(num_nodes, dtype=torch.bool)\n",
        "test_mask = torch.zeros(num_nodes, dtype=torch.bool)\n",
        "train_mask[:n_train] = True\n",
        "val_mask[n_train : n_train + n_val] = True\n",
        "test_mask[n_train + n_val :] = True\n",
        "\n",
        "graph_data_obj['transaction'].train_mask = train_mask\n",
        "graph_data_obj['transaction'].val_mask = val_mask\n",
        "graph_data_obj['transaction'].test_mask = test_mask\n",
        "print(f\"Train: {train_mask.sum()}, Val: {val_mask.sum()}, Test: {test_mask.sum()}\")"
      ],
      "metadata": {
        "id": "aQsx_p6UUR5w",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "00bbec9d-55a7-4667-88fc-566b1e2259cf"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Phase 2: Graph Construction ---\n",
            "Creating 'shared_card_identity' edges for 'card_identity_key'...\n",
            "    Added 779594 'shared_card_identity' (and reverse) edges.\n",
            "Creating 'shared_email_P' edges for 'P_emaildomain'...\n",
            "    Added 2679 'shared_email_P' (and reverse) edges.\n",
            "Creating 'shared_device_info' edges for 'DeviceInfo'...\n",
            "    Added 94944 'shared_device_info' (and reverse) edges.\n",
            "Creating 'temporal_proximity' edges...\n",
            "    Added 16416571 'temporal_proximity' (and reverse) edges.\n",
            "\n",
            "Creating 'similar_amount' edges using FAISS ANN...\n",
            "    FAISS Error: input not a numpy array.\n",
            "\n",
            "Graph construction summary:\n",
            "HeteroData(\n",
            "  transaction={\n",
            "    x=[458923, 164],\n",
            "    y=[458923, 1],\n",
            "    num_nodes=458923,\n",
            "  },\n",
            "  (transaction, shared_card_identity, transaction)={ edge_index=[2, 779594] },\n",
            "  (transaction, rev_shared_card_identity, transaction)={ edge_index=[2, 779594] },\n",
            "  (transaction, shared_email_P, transaction)={ edge_index=[2, 2679] },\n",
            "  (transaction, rev_shared_email_P, transaction)={ edge_index=[2, 2679] },\n",
            "  (transaction, shared_device_info, transaction)={ edge_index=[2, 94944] },\n",
            "  (transaction, rev_shared_device_info, transaction)={ edge_index=[2, 94944] },\n",
            "  (transaction, temporal_proximity, transaction)={ edge_index=[2, 16416571] },\n",
            "  (transaction, rev_temporal_proximity, transaction)={ edge_index=[2, 16416571] },\n",
            "  (transaction, similar_amount, transaction)={ edge_index=[2, 0] },\n",
            "  (transaction, rev_similar_amount, transaction)={ edge_index=[2, 0] }\n",
            ")\n",
            "Edge types for HeteroConv: [('transaction', 'shared_card_identity', 'transaction'), ('transaction', 'rev_shared_card_identity', 'transaction'), ('transaction', 'shared_email_P', 'transaction'), ('transaction', 'rev_shared_email_P', 'transaction'), ('transaction', 'shared_device_info', 'transaction'), ('transaction', 'rev_shared_device_info', 'transaction'), ('transaction', 'temporal_proximity', 'transaction'), ('transaction', 'rev_temporal_proximity', 'transaction')]\n",
            "Train: 321246, Val: 68838, Test: 68839\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Phase 3: GNN Architecture Design ---\n",
        "print(\"\\n--- Phase 3: GNN Architecture ---\")\n",
        "class HeteroGNN(torch.nn.Module):\n",
        "    def __init__(self, input_node_features, hidden_channels, out_channels, num_layers, dropout_rate, model_metadata_edge_tuples):\n",
        "        super().__init__()\n",
        "        self.dropout_rate = dropout_rate\n",
        "        self.num_layers = num_layers\n",
        "        self.convs = torch.nn.ModuleList()\n",
        "        self.lins = torch.nn.ModuleList()\n",
        "        self.bns = torch.nn.ModuleList()\n",
        "\n",
        "        self.initial_lin = Linear(input_node_features, hidden_channels)\n",
        "        self.initial_bn = torch.nn.BatchNorm1d(hidden_channels)\n",
        "\n",
        "        if not model_metadata_edge_tuples: raise ValueError(\"model_metadata_edge_tuples cannot be empty.\")\n",
        "        for i in range(num_layers):\n",
        "            conv_dict = {\n",
        "                full_edge_type_tuple: SAGEConv((-1, -1), hidden_channels, aggr='mean', normalize=False)\n",
        "                for full_edge_type_tuple in model_metadata_edge_tuples\n",
        "            }\n",
        "            if not conv_dict: raise ValueError(\"conv_dict became empty for HeteroConv.\")\n",
        "            self.convs.append(HeteroConv(conv_dict, aggr='sum'))\n",
        "            self.bns.append(torch.nn.BatchNorm1d(hidden_channels))\n",
        "            if i < num_layers - 1:\n",
        "                 self.lins.append(Linear(hidden_channels, hidden_channels))\n",
        "        self.out_lin = Linear(hidden_channels, out_channels)\n",
        "\n",
        "    def forward(self, x_dict, edge_index_dict):\n",
        "        current_x = x_dict['transaction']\n",
        "        current_x = self.initial_lin(current_x)\n",
        "        current_x = self.initial_bn(current_x)\n",
        "        current_x = F.leaky_relu(current_x)\n",
        "        current_x = F.dropout(current_x, p=self.dropout_rate, training=self.training)\n",
        "        x_dict_processed = {'transaction': current_x}\n",
        "\n",
        "        for i, conv_layer in enumerate(self.convs):\n",
        "            # Ensure all edge types expected by conv_layer are in edge_index_dict\n",
        "            # PyG's HeteroConv handles missing edge types in edge_index_dict gracefully if they are in its definition\n",
        "            x_dict_interim = conv_layer(x_dict_processed, edge_index_dict)\n",
        "            x_trans = x_dict_interim['transaction']\n",
        "\n",
        "            x_trans = self.bns[i](x_trans)\n",
        "            x_trans = F.leaky_relu(x_trans)\n",
        "            x_trans = F.dropout(x_trans, p=self.dropout_rate, training=self.training)\n",
        "\n",
        "            # Apply intermediate linear layer if it exists for this layer\n",
        "            if i < len(self.lins): # Check against actual number of intermediate linear layers\n",
        "                x_trans = self.lins[i](x_trans)\n",
        "                # Potentially add another round of activation/dropout if desired after intermediate lins\n",
        "                # x_trans = F.leaky_relu(x_trans)\n",
        "                # x_trans = F.dropout(x_trans, p=self.dropout_rate, training=self.training)\n",
        "\n",
        "\n",
        "            x_dict_processed = {'transaction': x_trans}\n",
        "\n",
        "        transaction_logits = self.out_lin(x_dict_processed['transaction'])\n",
        "        return {'transaction': transaction_logits}\n",
        "\n",
        "# Model instantiation\n",
        "HIDDEN_CHANNELS = 256\n",
        "OUT_CHANNELS = 1 # Binary Classification\n",
        "NUM_GNN_LAYERS = 3\n",
        "DROPOUT_RATE = 0.4\n",
        "\n",
        "model = HeteroGNN(input_node_features=num_node_features,\n",
        "                  hidden_channels=HIDDEN_CHANNELS,\n",
        "                  out_channels=OUT_CHANNELS,\n",
        "                  num_layers=NUM_GNN_LAYERS,\n",
        "                  dropout_rate=DROPOUT_RATE,\n",
        "                  model_metadata_edge_tuples=model_edge_types) # Ensure model_edge_types is correct\n",
        "print(model)\n",
        "model = model.to(DEVICE)"
      ],
      "metadata": {
        "id": "X2JzqboadtGA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "310e1431-134f-444a-87ff-af258f2a86b8"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Phase 3: GNN Architecture ---\n",
            "HeteroGNN(\n",
            "  (convs): ModuleList(\n",
            "    (0-2): 3 x HeteroConv(num_relations=8)\n",
            "  )\n",
            "  (lins): ModuleList(\n",
            "    (0-1): 2 x Linear(256, 256, bias=True)\n",
            "  )\n",
            "  (bns): ModuleList(\n",
            "    (0-2): 3 x BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (initial_lin): Linear(164, 256, bias=True)\n",
            "  (initial_bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (out_lin): Linear(256, 1, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Phase 4: Model Training and Evaluation (with Mini-Batching) ---\n",
        "print(\"\\n--- Phase 4: Training and Evaluation (with Mini-Batching) ---\")\n",
        "\n",
        "BATCH_SIZE = 8192\n",
        "if NUM_GNN_LAYERS == 1: NUM_NEIGHBORS_PER_LAYER = [12] # MODIFIED (example)\n",
        "elif NUM_GNN_LAYERS == 2: NUM_NEIGHBORS_PER_LAYER = [12, 8] # MODIFIED\n",
        "elif NUM_GNN_LAYERS == 3: NUM_NEIGHBORS_PER_LAYER = [12, 8, 5] # MODIFIED (example)\n",
        "else: # Fallback for more layers\n",
        "    NUM_NEIGHBORS_PER_LAYER = [12, 8, 5] + [5] * (NUM_GNN_LAYERS - 3)\n",
        "\n",
        "print(f\"Using BATCH_SIZE: {BATCH_SIZE}\")\n",
        "print(f\"NUM_NEIGHBORS_PER_LAYER for {NUM_GNN_LAYERS} layers: {NUM_NEIGHBORS_PER_LAYER}\")\n",
        "\n",
        "train_input_nodes = ('transaction', graph_data_obj['transaction'].train_mask)\n",
        "val_input_nodes = ('transaction', graph_data_obj['transaction'].val_mask)\n",
        "test_input_nodes = ('transaction', graph_data_obj['transaction'].test_mask)\n",
        "\n",
        "NUM_WORKERS_LOADER = 2 if os.name == 'nt' else 2\n",
        "\n",
        "train_loader = NeighborLoader(\n",
        "    graph_data_obj, num_neighbors=NUM_NEIGHBORS_PER_LAYER,\n",
        "    input_nodes=train_input_nodes, batch_size=BATCH_SIZE,\n",
        "    shuffle=True, num_workers=NUM_WORKERS_LOADER, pin_memory=True if DEVICE.type == 'cuda' else False,\n",
        "    replace=False # Default, sample without replacement\n",
        ")\n",
        "val_loader = NeighborLoader(\n",
        "    graph_data_obj, num_neighbors=NUM_NEIGHBORS_PER_LAYER,\n",
        "    input_nodes=val_input_nodes, batch_size=BATCH_SIZE * 2,\n",
        "    shuffle=False, num_workers=NUM_WORKERS_LOADER, pin_memory=True if DEVICE.type == 'cuda' else False,\n",
        "    replace=False\n",
        ")\n",
        "test_loader = NeighborLoader(\n",
        "    graph_data_obj, num_neighbors=NUM_NEIGHBORS_PER_LAYER,\n",
        "    input_nodes=test_input_nodes, batch_size=BATCH_SIZE * 2,\n",
        "    shuffle=False, num_workers=NUM_WORKERS_LOADER, pin_memory=True if DEVICE.type == 'cuda' else False,\n",
        "    replace=False\n",
        ")\n",
        "\n",
        "train_labels_full = graph_data_obj['transaction'].y[graph_data_obj['transaction'].train_mask]\n",
        "pos_weight_tensor = None\n",
        "if len(train_labels_full) > 0:\n",
        "    n_pos = train_labels_full.sum().item()\n",
        "    n_neg = len(train_labels_full) - n_pos\n",
        "    if n_pos > 0 and n_neg > 0:\n",
        "        weight = min(n_neg / n_pos, 100.0)\n",
        "        pos_weight_tensor = torch.tensor([weight], device=DEVICE)\n",
        "        print(f\"Positive class weight: {pos_weight_tensor.item():.2f}\")\n",
        "criterion = torch.nn.BCEWithLogitsLoss(pos_weight=pos_weight_tensor)\n",
        "# MODIFIED: Increased weight_decay\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=0.001, weight_decay=1e-4)\n",
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'max', patience=10, factor=0.5, verbose=True)\n",
        "\n",
        "\n",
        "def train_epoch(current_model, loader, current_optimizer, current_criterion):\n",
        "    current_model.train()\n",
        "    total_loss = 0\n",
        "    num_batches = 0\n",
        "    for batch in loader:\n",
        "        batch = batch.to(DEVICE)\n",
        "        current_optimizer.zero_grad()\n",
        "\n",
        "        # Filter edge_index_dict for edges present in the current batch\n",
        "        # and expected by the model\n",
        "        batch_edge_index_dict = {\n",
        "            edge_type: batch.edge_index_dict[edge_type]\n",
        "            for edge_type in current_model.convs[0].convs.keys() # Get edge types from model def\n",
        "            if edge_type in batch.edge_index_dict and batch.edge_index_dict[edge_type].numel() > 0\n",
        "        }\n",
        "\n",
        "        out_logits = current_model(batch.x_dict, batch_edge_index_dict)\n",
        "        out_trans = out_logits['transaction']\n",
        "        loss = current_criterion(out_trans[:batch['transaction'].batch_size],\n",
        "                                 batch['transaction'].y[:batch['transaction'].batch_size])\n",
        "        if torch.isnan(loss): print(\"NaN loss detected in training!\"); continue\n",
        "        loss.backward()\n",
        "        current_optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "        num_batches += 1\n",
        "    return total_loss / num_batches if num_batches > 0 else 0\n",
        "\n",
        "@torch.no_grad()\n",
        "def evaluate_model(current_model, loader, current_criterion, threshold=0.5):\n",
        "    current_model.eval()\n",
        "    total_loss = 0\n",
        "    all_probs, all_targets = [], []\n",
        "    num_batches = 0\n",
        "    if loader is None or not hasattr(loader, 'dataset') or len(loader.dataset) == 0 or not loader.input_nodes[1].any():\n",
        "        print(\"Warning: Empty data loader or no input nodes for evaluation.\")\n",
        "        # Return structure consistent with normal path but indicating no data\n",
        "        return 0.0, 0.5, 0.0, 0.0, 0.0, 0.0, np.array([]), np.array([])\n",
        "\n",
        "\n",
        "    for batch in loader:\n",
        "        batch = batch.to(DEVICE)\n",
        "        batch_edge_index_dict = {\n",
        "            edge_type: batch.edge_index_dict[edge_type]\n",
        "            for edge_type in current_model.convs[0].convs.keys() # Get edge types from model def\n",
        "            if edge_type in batch.edge_index_dict and batch.edge_index_dict[edge_type].numel() > 0\n",
        "        }\n",
        "        out_logits = current_model(batch.x_dict, batch_edge_index_dict)\n",
        "        out_trans = out_logits['transaction']\n",
        "\n",
        "        batch_seed_logits = out_trans[:batch['transaction'].batch_size]\n",
        "        batch_seed_labels = batch['transaction'].y[:batch['transaction'].batch_size]\n",
        "\n",
        "        # Ensure batch_seed_labels is not empty before calculating loss\n",
        "        if batch_seed_labels.numel() == 0:\n",
        "            continue # Skip if this batch somehow has no labels (e.g. batch_size dropped to 0)\n",
        "\n",
        "        loss = current_criterion(batch_seed_logits, batch_seed_labels).item()\n",
        "        total_loss += loss\n",
        "        num_batches += 1\n",
        "        all_probs.append(torch.sigmoid(batch_seed_logits).cpu())\n",
        "        all_targets.append(batch_seed_labels.cpu())\n",
        "\n",
        "    if num_batches == 0: # No batches were processed\n",
        "        print(\"Warning: No batches processed in evaluate_model.\")\n",
        "        return 0.0, 0.5, 0.0, 0.0, 0.0, 0.0, np.array([]), np.array([])\n",
        "\n",
        "    avg_loss = total_loss / num_batches\n",
        "    if not all_probs: return avg_loss, 0.5, 0.0, 0.0, 0.0, 0.0, np.array([]), np.array([])\n",
        "\n",
        "    probs_np = torch.cat(all_probs).numpy().flatten()\n",
        "    targets_np = torch.cat(all_targets).numpy().flatten()\n",
        "\n",
        "    # Handle cases where targets_np might be empty after filtering\n",
        "    if len(targets_np) == 0:\n",
        "        print(\"Warning: No targets available for metric calculation after processing batches.\")\n",
        "        return avg_loss, 0.5, 0.0, 0.0, 0.0, 0.0, np.array([]), np.array([])\n",
        "\n",
        "    preds_np = (probs_np > threshold).astype(int)\n",
        "\n",
        "    if len(np.unique(targets_np)) < 2:\n",
        "        auc_roc = 0.5 # Default for single class\n",
        "        # AUCPR can still be calculated if there's at least one positive or negative instance,\n",
        "        # but its interpretation is tricky. sklearn handles this.\n",
        "        auc_pr = average_precision_score(targets_np, probs_np)\n",
        "    else:\n",
        "        auc_roc = roc_auc_score(targets_np, probs_np)\n",
        "        auc_pr = average_precision_score(targets_np, probs_np)\n",
        "\n",
        "    precision = precision_score(targets_np, preds_np, zero_division=0)\n",
        "    recall = recall_score(targets_np, preds_np, zero_division=0)\n",
        "    f1 = f1_score(targets_np, preds_np, zero_division=0)\n",
        "    return avg_loss, auc_roc, auc_pr, precision, recall, f1, preds_np, targets_np\n",
        "\n",
        "# Training loop\n",
        "EPOCHS = 150 # Reduced epochs for faster iteration, can be increased\n",
        "PATIENCE_EARLY_STOPPING = 30 # Reduced patience slightly\n",
        "best_val_aucpr = 0\n",
        "best_epoch = 0\n",
        "patience_counter = 0\n",
        "model_save_path = 'best_hetero_gnn_fraud_batched_v2.pth' # New model name\n",
        "\n",
        "print(\"Starting training with mini-batching...\")\n",
        "for epoch in range(1, EPOCHS + 1):\n",
        "    epoch_start_time = time.time()\n",
        "    train_loss = train_epoch(model, train_loader, optimizer, criterion)\n",
        "    val_loss, val_auc_roc, val_auc_pr, val_precision, val_recall, val_f1, _, _ = evaluate_model(\n",
        "        model, val_loader, criterion\n",
        "    )\n",
        "    epoch_duration = time.time() - epoch_start_time\n",
        "    print(f'Epoch: {epoch:03d} | Time: {epoch_duration:.2f}s | LR: {optimizer.param_groups[0][\"lr\"]:.1e} | Train Loss: {train_loss:.4f} | '\n",
        "          f'Val Loss: {val_loss:.4f} | Val AUCPR: {val_auc_pr:.4f} | Val F1: {val_f1:.4f}')\n",
        "\n",
        "    scheduler.step(val_auc_pr)\n",
        "\n",
        "    if val_auc_pr > best_val_aucpr:\n",
        "        best_val_aucpr = val_auc_pr\n",
        "        best_epoch = epoch\n",
        "        patience_counter = 0\n",
        "        torch.save(model.state_dict(), model_save_path)\n",
        "        print(f\"Epoch {epoch}: New best val AUCPR: {best_val_aucpr:.4f}. Model saved.\")\n",
        "    else:\n",
        "        patience_counter += 1\n",
        "    if patience_counter >= PATIENCE_EARLY_STOPPING:\n",
        "        print(f\"Early stopping at epoch {epoch}.\")\n",
        "        break\n",
        "\n",
        "if os.path.exists(model_save_path):\n",
        "    print(f\"\\nLoading best model from epoch {best_epoch} (Val AUCPR: {best_val_aucpr:.4f}).\")\n",
        "    model.load_state_dict(torch.load(model_save_path, map_location=DEVICE))\n",
        "else:\n",
        "    print(\"\\nNo best model found or saved. Using last epoch model for testing.\")\n",
        "\n",
        "test_loss, test_auc_roc, test_auc_pr, test_precision, test_recall, test_f1, test_preds, test_targets = evaluate_model(\n",
        "    model, test_loader, criterion\n",
        ")\n",
        "print(f'\\n--- Test Set Evaluation (Mini-Batching) ---')\n",
        "print(f'Test Loss: {test_loss:.4f} | AUROC: {test_auc_roc:.4f} | AUCPR: {test_auc_pr:.4f}')\n",
        "print(f'Test F1: {test_f1:.4f} | Precision: {test_precision:.4f} | Recall: {test_recall:.4f}')\n",
        "\n",
        "if len(test_targets) > 0 and len(test_preds) > 0:\n",
        "    cm = confusion_matrix(test_targets, test_preds)\n",
        "    plt.figure(figsize=(6,5))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Legit', 'Fraud'], yticklabels=['Legit', 'Fraud'])\n",
        "    plt.xlabel('Predicted Label'); plt.ylabel('True Label'); plt.title('Test Set Confusion Matrix')\n",
        "    plt.savefig('test_confusion_matrix_batched_v2.png')\n",
        "    print(\"Saved confusion matrix to test_confusion_matrix_batched_v2.png\")\n",
        "\n",
        "    fp_cost, fn_cost = 1, 100 # Example costs\n",
        "    tn, fp, fn, tp = cm.ravel() if cm.size == 4 else (0,0,0,0) # Handle empty cm\n",
        "    total_cost = (fp * fp_cost) + (fn * fn_cost)\n",
        "    print(f\"Total Estimated Financial Cost (Test): ${total_cost}\") # Ensure TP/FP/FN/TN are integers\n",
        "else:\n",
        "    print(\"Test set empty or no predictions. Skipping CM and cost.\")"
      ],
      "metadata": {
        "id": "BK3S1RWaUUqC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "e03f9c5c-3783-4cf4-aaa3-c9bf88531fe6"
      },
      "execution_count": 7,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Phase 4: Training and Evaluation (with Mini-Batching) ---\n",
            "Using BATCH_SIZE: 8192\n",
            "NUM_NEIGHBORS_PER_LAYER for 3 layers: [12, 8, 5]\n",
            "Positive class weight: 28.36\n",
            "Starting training with mini-batching...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 001 | Time: 44.10s | LR: 1.0e-03 | Train Loss: 1.2870 | Val Loss: 1.2650 | Val AUCPR: 0.1107 | Val F1: 0.1599\n",
            "Epoch 1: New best val AUCPR: 0.1107. Model saved.\n",
            "Epoch: 002 | Time: 42.68s | LR: 1.0e-03 | Train Loss: 1.2161 | Val Loss: 1.2569 | Val AUCPR: 0.1204 | Val F1: 0.1586\n",
            "Epoch 2: New best val AUCPR: 0.1204. Model saved.\n",
            "Epoch: 003 | Time: 42.80s | LR: 1.0e-03 | Train Loss: 1.1702 | Val Loss: 1.3500 | Val AUCPR: 0.1278 | Val F1: 0.0824\n",
            "Epoch 3: New best val AUCPR: 0.1278. Model saved.\n",
            "Epoch: 004 | Time: 42.29s | LR: 1.0e-03 | Train Loss: 1.1117 | Val Loss: 1.2403 | Val AUCPR: 0.1580 | Val F1: 0.1569\n",
            "Epoch 4: New best val AUCPR: 0.1580. Model saved.\n",
            "Epoch: 005 | Time: 43.46s | LR: 1.0e-03 | Train Loss: 1.0839 | Val Loss: 1.3841 | Val AUCPR: 0.1675 | Val F1: 0.0881\n",
            "Epoch 5: New best val AUCPR: 0.1675. Model saved.\n",
            "Epoch: 006 | Time: 43.38s | LR: 1.0e-03 | Train Loss: 1.0618 | Val Loss: 1.3319 | Val AUCPR: 0.1602 | Val F1: 0.0911\n",
            "Epoch: 007 | Time: 42.87s | LR: 1.0e-03 | Train Loss: 1.0397 | Val Loss: 1.2054 | Val AUCPR: 0.1949 | Val F1: 0.1349\n",
            "Epoch 7: New best val AUCPR: 0.1949. Model saved.\n",
            "Epoch: 008 | Time: 42.28s | LR: 1.0e-03 | Train Loss: 1.0320 | Val Loss: 1.6342 | Val AUCPR: 0.2094 | Val F1: 0.0830\n",
            "Epoch 8: New best val AUCPR: 0.2094. Model saved.\n",
            "Epoch: 009 | Time: 42.39s | LR: 1.0e-03 | Train Loss: 1.0145 | Val Loss: 1.2714 | Val AUCPR: 0.2284 | Val F1: 0.0972\n",
            "Epoch 9: New best val AUCPR: 0.2284. Model saved.\n",
            "Epoch: 010 | Time: 43.18s | LR: 1.0e-03 | Train Loss: 1.0032 | Val Loss: 1.6471 | Val AUCPR: 0.2000 | Val F1: 0.0831\n",
            "Epoch: 011 | Time: 42.96s | LR: 1.0e-03 | Train Loss: 0.9922 | Val Loss: 1.4749 | Val AUCPR: 0.2525 | Val F1: 0.0829\n",
            "Epoch 11: New best val AUCPR: 0.2525. Model saved.\n",
            "Epoch: 012 | Time: 42.76s | LR: 1.0e-03 | Train Loss: 0.9968 | Val Loss: 1.1822 | Val AUCPR: 0.2497 | Val F1: 0.1574\n",
            "Epoch: 013 | Time: 42.74s | LR: 1.0e-03 | Train Loss: 0.9752 | Val Loss: 1.5829 | Val AUCPR: 0.2666 | Val F1: 0.0879\n",
            "Epoch 13: New best val AUCPR: 0.2666. Model saved.\n",
            "Epoch: 014 | Time: 43.14s | LR: 1.0e-03 | Train Loss: 0.9762 | Val Loss: 1.1492 | Val AUCPR: 0.2628 | Val F1: 0.1140\n",
            "Epoch: 015 | Time: 42.77s | LR: 1.0e-03 | Train Loss: 0.9706 | Val Loss: 1.1583 | Val AUCPR: 0.2751 | Val F1: 0.2102\n",
            "Epoch 15: New best val AUCPR: 0.2751. Model saved.\n",
            "Epoch: 016 | Time: 43.13s | LR: 1.0e-03 | Train Loss: 0.9757 | Val Loss: 1.0732 | Val AUCPR: 0.2819 | Val F1: 0.1741\n",
            "Epoch 16: New best val AUCPR: 0.2819. Model saved.\n",
            "Epoch: 017 | Time: 43.45s | LR: 1.0e-03 | Train Loss: 0.9617 | Val Loss: 1.1029 | Val AUCPR: 0.2781 | Val F1: 0.1326\n",
            "Epoch: 018 | Time: 42.11s | LR: 1.0e-03 | Train Loss: 0.9528 | Val Loss: 1.3082 | Val AUCPR: 0.2611 | Val F1: 0.0911\n",
            "Epoch: 019 | Time: 42.87s | LR: 1.0e-03 | Train Loss: 0.9572 | Val Loss: 1.1035 | Val AUCPR: 0.2505 | Val F1: 0.1618\n",
            "Epoch: 020 | Time: 42.62s | LR: 1.0e-03 | Train Loss: 0.9583 | Val Loss: 1.1734 | Val AUCPR: 0.2589 | Val F1: 0.1164\n",
            "Epoch: 021 | Time: 43.24s | LR: 1.0e-03 | Train Loss: 0.9386 | Val Loss: 1.1155 | Val AUCPR: 0.2857 | Val F1: 0.1929\n",
            "Epoch 21: New best val AUCPR: 0.2857. Model saved.\n",
            "Epoch: 022 | Time: 42.97s | LR: 1.0e-03 | Train Loss: 0.9429 | Val Loss: 1.3680 | Val AUCPR: 0.2686 | Val F1: 0.2999\n",
            "Epoch: 023 | Time: 42.78s | LR: 1.0e-03 | Train Loss: 0.9426 | Val Loss: 1.2405 | Val AUCPR: 0.2603 | Val F1: 0.2509\n",
            "Epoch: 024 | Time: 42.24s | LR: 1.0e-03 | Train Loss: 0.9369 | Val Loss: 1.0920 | Val AUCPR: 0.2868 | Val F1: 0.2014\n",
            "Epoch 24: New best val AUCPR: 0.2868. Model saved.\n",
            "Epoch: 025 | Time: 43.03s | LR: 1.0e-03 | Train Loss: 0.9303 | Val Loss: 1.2044 | Val AUCPR: 0.2887 | Val F1: 0.2911\n",
            "Epoch 25: New best val AUCPR: 0.2887. Model saved.\n",
            "Epoch: 026 | Time: 42.98s | LR: 1.0e-03 | Train Loss: 0.9317 | Val Loss: 1.2933 | Val AUCPR: 0.2125 | Val F1: 0.1021\n",
            "Epoch: 027 | Time: 42.86s | LR: 1.0e-03 | Train Loss: 0.9319 | Val Loss: 1.3450 | Val AUCPR: 0.2593 | Val F1: 0.0974\n",
            "Epoch: 028 | Time: 43.11s | LR: 1.0e-03 | Train Loss: 0.9266 | Val Loss: 1.3155 | Val AUCPR: 0.2569 | Val F1: 0.0964\n",
            "Epoch: 029 | Time: 43.28s | LR: 1.0e-03 | Train Loss: 0.9195 | Val Loss: 1.1567 | Val AUCPR: 0.2826 | Val F1: 0.1091\n",
            "Epoch: 030 | Time: 42.75s | LR: 1.0e-03 | Train Loss: 0.9098 | Val Loss: 1.0745 | Val AUCPR: 0.2792 | Val F1: 0.1382\n",
            "Epoch: 031 | Time: 42.21s | LR: 1.0e-03 | Train Loss: 0.9179 | Val Loss: 1.7485 | Val AUCPR: 0.2346 | Val F1: 0.0841\n",
            "Epoch: 032 | Time: 42.79s | LR: 1.0e-03 | Train Loss: 0.9077 | Val Loss: 1.1254 | Val AUCPR: 0.2117 | Val F1: 0.1467\n",
            "Epoch: 033 | Time: 42.37s | LR: 1.0e-03 | Train Loss: 0.9068 | Val Loss: 1.0849 | Val AUCPR: 0.2782 | Val F1: 0.1452\n",
            "Epoch: 034 | Time: 42.45s | LR: 1.0e-03 | Train Loss: 0.9057 | Val Loss: 1.1482 | Val AUCPR: 0.2927 | Val F1: 0.2418\n",
            "Epoch 34: New best val AUCPR: 0.2927. Model saved.\n",
            "Epoch: 035 | Time: 42.36s | LR: 1.0e-03 | Train Loss: 0.9024 | Val Loss: 1.1609 | Val AUCPR: 0.2519 | Val F1: 0.1189\n",
            "Epoch: 036 | Time: 42.98s | LR: 1.0e-03 | Train Loss: 0.9037 | Val Loss: 1.0818 | Val AUCPR: 0.2903 | Val F1: 0.2028\n",
            "Epoch: 037 | Time: 44.01s | LR: 1.0e-03 | Train Loss: 0.8938 | Val Loss: 1.2540 | Val AUCPR: 0.2795 | Val F1: 0.2678\n",
            "Epoch: 038 | Time: 42.49s | LR: 1.0e-03 | Train Loss: 0.8961 | Val Loss: 1.1072 | Val AUCPR: 0.2608 | Val F1: 0.1318\n",
            "Epoch: 039 | Time: 42.92s | LR: 1.0e-03 | Train Loss: 0.8923 | Val Loss: 1.0886 | Val AUCPR: 0.2916 | Val F1: 0.2068\n",
            "Epoch: 040 | Time: 42.77s | LR: 1.0e-03 | Train Loss: 0.8928 | Val Loss: 1.0765 | Val AUCPR: 0.2741 | Val F1: 0.1660\n",
            "Epoch: 041 | Time: 43.85s | LR: 1.0e-03 | Train Loss: 0.8993 | Val Loss: 1.1174 | Val AUCPR: 0.2596 | Val F1: 0.1930\n",
            "Epoch: 042 | Time: 42.92s | LR: 1.0e-03 | Train Loss: 0.8819 | Val Loss: 1.0819 | Val AUCPR: 0.3094 | Val F1: 0.2184\n",
            "Epoch 42: New best val AUCPR: 0.3094. Model saved.\n",
            "Epoch: 043 | Time: 42.58s | LR: 1.0e-03 | Train Loss: 0.8931 | Val Loss: 1.4389 | Val AUCPR: 0.2325 | Val F1: 0.0916\n",
            "Epoch: 044 | Time: 42.76s | LR: 1.0e-03 | Train Loss: 0.8867 | Val Loss: 1.0561 | Val AUCPR: 0.2922 | Val F1: 0.1495\n",
            "Epoch: 045 | Time: 42.99s | LR: 1.0e-03 | Train Loss: 0.8854 | Val Loss: 1.0536 | Val AUCPR: 0.2899 | Val F1: 0.1886\n",
            "Epoch: 046 | Time: 43.46s | LR: 1.0e-03 | Train Loss: 0.8862 | Val Loss: 1.1181 | Val AUCPR: 0.2972 | Val F1: 0.2262\n",
            "Epoch: 047 | Time: 42.55s | LR: 1.0e-03 | Train Loss: 0.8736 | Val Loss: 1.1196 | Val AUCPR: 0.2940 | Val F1: 0.2222\n",
            "Epoch: 048 | Time: 43.01s | LR: 1.0e-03 | Train Loss: 0.8774 | Val Loss: 1.2525 | Val AUCPR: 0.2932 | Val F1: 0.2922\n",
            "Epoch: 049 | Time: 42.48s | LR: 1.0e-03 | Train Loss: 0.8736 | Val Loss: 1.1895 | Val AUCPR: 0.2514 | Val F1: 0.1724\n",
            "Epoch: 050 | Time: 42.82s | LR: 1.0e-03 | Train Loss: 0.8729 | Val Loss: 1.1162 | Val AUCPR: 0.2440 | Val F1: 0.1442\n",
            "Epoch: 051 | Time: 43.27s | LR: 1.0e-03 | Train Loss: 0.8837 | Val Loss: 1.1437 | Val AUCPR: 0.2784 | Val F1: 0.1256\n",
            "Epoch: 052 | Time: 43.38s | LR: 1.0e-03 | Train Loss: 0.8656 | Val Loss: 1.2387 | Val AUCPR: 0.2811 | Val F1: 0.2360\n",
            "Epoch: 053 | Time: 43.03s | LR: 1.0e-03 | Train Loss: 0.8670 | Val Loss: 1.1408 | Val AUCPR: 0.2885 | Val F1: 0.1258\n",
            "Epoch: 054 | Time: 43.11s | LR: 5.0e-04 | Train Loss: 0.8499 | Val Loss: 1.1005 | Val AUCPR: 0.3205 | Val F1: 0.2320\n",
            "Epoch 54: New best val AUCPR: 0.3205. Model saved.\n",
            "Epoch: 055 | Time: 42.90s | LR: 5.0e-04 | Train Loss: 0.8388 | Val Loss: 1.1255 | Val AUCPR: 0.2921 | Val F1: 0.2341\n",
            "Epoch: 056 | Time: 43.69s | LR: 5.0e-04 | Train Loss: 0.8389 | Val Loss: 1.1564 | Val AUCPR: 0.3088 | Val F1: 0.2570\n",
            "Epoch: 057 | Time: 43.15s | LR: 5.0e-04 | Train Loss: 0.8345 | Val Loss: 1.1756 | Val AUCPR: 0.2951 | Val F1: 0.1136\n",
            "Epoch: 058 | Time: 43.55s | LR: 5.0e-04 | Train Loss: 0.8329 | Val Loss: 1.1093 | Val AUCPR: 0.3136 | Val F1: 0.2333\n",
            "Epoch: 059 | Time: 43.10s | LR: 5.0e-04 | Train Loss: 0.8290 | Val Loss: 1.2342 | Val AUCPR: 0.3056 | Val F1: 0.2611\n",
            "Epoch: 060 | Time: 43.52s | LR: 5.0e-04 | Train Loss: 0.8249 | Val Loss: 1.1268 | Val AUCPR: 0.2968 | Val F1: 0.2537\n",
            "Epoch: 061 | Time: 43.39s | LR: 5.0e-04 | Train Loss: 0.8261 | Val Loss: 1.1659 | Val AUCPR: 0.2915 | Val F1: 0.1290\n",
            "Epoch: 062 | Time: 43.31s | LR: 5.0e-04 | Train Loss: 0.8216 | Val Loss: 1.1043 | Val AUCPR: 0.3116 | Val F1: 0.2275\n",
            "Epoch: 063 | Time: 43.65s | LR: 5.0e-04 | Train Loss: 0.8234 | Val Loss: 1.0397 | Val AUCPR: 0.2967 | Val F1: 0.1811\n",
            "Epoch: 064 | Time: 43.26s | LR: 5.0e-04 | Train Loss: 0.8172 | Val Loss: 1.0696 | Val AUCPR: 0.3182 | Val F1: 0.2087\n",
            "Epoch: 065 | Time: 42.75s | LR: 5.0e-04 | Train Loss: 0.8168 | Val Loss: 1.0422 | Val AUCPR: 0.3275 | Val F1: 0.2180\n",
            "Epoch 65: New best val AUCPR: 0.3275. Model saved.\n",
            "Epoch: 066 | Time: 43.27s | LR: 5.0e-04 | Train Loss: 0.8172 | Val Loss: 1.0783 | Val AUCPR: 0.3156 | Val F1: 0.2314\n",
            "Epoch: 067 | Time: 43.13s | LR: 5.0e-04 | Train Loss: 0.8156 | Val Loss: 1.0892 | Val AUCPR: 0.2895 | Val F1: 0.1975\n",
            "Epoch: 068 | Time: 43.70s | LR: 5.0e-04 | Train Loss: 0.8109 | Val Loss: 1.1137 | Val AUCPR: 0.3088 | Val F1: 0.1912\n",
            "Epoch: 069 | Time: 42.56s | LR: 5.0e-04 | Train Loss: 0.8129 | Val Loss: 1.0612 | Val AUCPR: 0.2939 | Val F1: 0.1699\n",
            "Epoch: 070 | Time: 42.64s | LR: 5.0e-04 | Train Loss: 0.8189 | Val Loss: 1.0713 | Val AUCPR: 0.3099 | Val F1: 0.1569\n",
            "Epoch: 071 | Time: 42.44s | LR: 5.0e-04 | Train Loss: 0.8160 | Val Loss: 1.0899 | Val AUCPR: 0.2915 | Val F1: 0.1466\n",
            "Epoch: 072 | Time: 42.60s | LR: 5.0e-04 | Train Loss: 0.8112 | Val Loss: 1.0785 | Val AUCPR: 0.2965 | Val F1: 0.1446\n",
            "Epoch: 073 | Time: 42.25s | LR: 5.0e-04 | Train Loss: 0.8025 | Val Loss: 1.0359 | Val AUCPR: 0.3202 | Val F1: 0.2006\n",
            "Epoch: 074 | Time: 42.75s | LR: 5.0e-04 | Train Loss: 0.8019 | Val Loss: 1.2509 | Val AUCPR: 0.3091 | Val F1: 0.2680\n",
            "Epoch: 075 | Time: 42.84s | LR: 5.0e-04 | Train Loss: 0.8040 | Val Loss: 1.0461 | Val AUCPR: 0.3049 | Val F1: 0.1743\n",
            "Epoch: 076 | Time: 42.51s | LR: 5.0e-04 | Train Loss: 0.8034 | Val Loss: 1.1489 | Val AUCPR: 0.3115 | Val F1: 0.2470\n",
            "Epoch: 077 | Time: 42.67s | LR: 2.5e-04 | Train Loss: 0.7923 | Val Loss: 1.0338 | Val AUCPR: 0.3233 | Val F1: 0.1974\n",
            "Epoch: 078 | Time: 42.28s | LR: 2.5e-04 | Train Loss: 0.7847 | Val Loss: 1.1380 | Val AUCPR: 0.3122 | Val F1: 0.2466\n",
            "Epoch: 079 | Time: 42.35s | LR: 2.5e-04 | Train Loss: 0.7887 | Val Loss: 1.0809 | Val AUCPR: 0.3173 | Val F1: 0.2152\n",
            "Epoch: 080 | Time: 42.71s | LR: 2.5e-04 | Train Loss: 0.7867 | Val Loss: 1.0426 | Val AUCPR: 0.3248 | Val F1: 0.1806\n",
            "Epoch: 081 | Time: 42.50s | LR: 2.5e-04 | Train Loss: 0.7801 | Val Loss: 1.1767 | Val AUCPR: 0.3157 | Val F1: 0.2677\n",
            "Epoch: 082 | Time: 42.46s | LR: 2.5e-04 | Train Loss: 0.7771 | Val Loss: 1.0701 | Val AUCPR: 0.3143 | Val F1: 0.1720\n",
            "Epoch: 083 | Time: 42.77s | LR: 2.5e-04 | Train Loss: 0.7795 | Val Loss: 1.0945 | Val AUCPR: 0.3223 | Val F1: 0.2200\n",
            "Epoch: 084 | Time: 42.52s | LR: 2.5e-04 | Train Loss: 0.7750 | Val Loss: 1.0814 | Val AUCPR: 0.3274 | Val F1: 0.2221\n",
            "Epoch: 085 | Time: 42.81s | LR: 2.5e-04 | Train Loss: 0.7720 | Val Loss: 1.1792 | Val AUCPR: 0.3277 | Val F1: 0.2604\n",
            "Epoch 85: New best val AUCPR: 0.3277. Model saved.\n",
            "Epoch: 086 | Time: 42.19s | LR: 2.5e-04 | Train Loss: 0.7721 | Val Loss: 1.0800 | Val AUCPR: 0.3196 | Val F1: 0.2150\n",
            "Epoch: 087 | Time: 42.12s | LR: 2.5e-04 | Train Loss: 0.7660 | Val Loss: 1.0474 | Val AUCPR: 0.3217 | Val F1: 0.1771\n",
            "Epoch: 088 | Time: 42.89s | LR: 2.5e-04 | Train Loss: 0.7699 | Val Loss: 1.1188 | Val AUCPR: 0.3192 | Val F1: 0.2492\n",
            "Epoch: 089 | Time: 42.24s | LR: 2.5e-04 | Train Loss: 0.7669 | Val Loss: 1.0745 | Val AUCPR: 0.3116 | Val F1: 0.1806\n",
            "Epoch: 090 | Time: 42.29s | LR: 2.5e-04 | Train Loss: 0.7624 | Val Loss: 1.0914 | Val AUCPR: 0.3108 | Val F1: 0.2069\n",
            "Epoch: 091 | Time: 42.79s | LR: 2.5e-04 | Train Loss: 0.7677 | Val Loss: 1.0746 | Val AUCPR: 0.3271 | Val F1: 0.2209\n",
            "Epoch: 092 | Time: 42.36s | LR: 2.5e-04 | Train Loss: 0.7650 | Val Loss: 1.0619 | Val AUCPR: 0.3061 | Val F1: 0.1733\n",
            "Epoch: 093 | Time: 42.26s | LR: 2.5e-04 | Train Loss: 0.7655 | Val Loss: 1.1205 | Val AUCPR: 0.2887 | Val F1: 0.2191\n",
            "Epoch: 094 | Time: 42.29s | LR: 2.5e-04 | Train Loss: 0.7617 | Val Loss: 1.0564 | Val AUCPR: 0.3237 | Val F1: 0.1858\n",
            "Epoch: 095 | Time: 42.26s | LR: 2.5e-04 | Train Loss: 0.7622 | Val Loss: 1.1025 | Val AUCPR: 0.2987 | Val F1: 0.1907\n",
            "Epoch: 096 | Time: 42.52s | LR: 2.5e-04 | Train Loss: 0.7623 | Val Loss: 1.0660 | Val AUCPR: 0.3119 | Val F1: 0.2154\n",
            "Epoch: 097 | Time: 42.53s | LR: 1.3e-04 | Train Loss: 0.7531 | Val Loss: 1.1615 | Val AUCPR: 0.3229 | Val F1: 0.2536\n",
            "Epoch: 098 | Time: 42.35s | LR: 1.3e-04 | Train Loss: 0.7515 | Val Loss: 1.0589 | Val AUCPR: 0.3264 | Val F1: 0.2056\n",
            "Epoch: 099 | Time: 42.22s | LR: 1.3e-04 | Train Loss: 0.7503 | Val Loss: 1.0747 | Val AUCPR: 0.3269 | Val F1: 0.2034\n",
            "Epoch: 100 | Time: 42.51s | LR: 1.3e-04 | Train Loss: 0.7444 | Val Loss: 1.0612 | Val AUCPR: 0.3247 | Val F1: 0.1843\n",
            "Epoch: 101 | Time: 42.20s | LR: 1.3e-04 | Train Loss: 0.7506 | Val Loss: 1.1197 | Val AUCPR: 0.3199 | Val F1: 0.2433\n",
            "Epoch: 102 | Time: 42.14s | LR: 1.3e-04 | Train Loss: 0.7414 | Val Loss: 1.0687 | Val AUCPR: 0.3265 | Val F1: 0.2082\n",
            "Epoch: 103 | Time: 42.13s | LR: 1.3e-04 | Train Loss: 0.7490 | Val Loss: 1.1338 | Val AUCPR: 0.3280 | Val F1: 0.2438\n",
            "Epoch 103: New best val AUCPR: 0.3280. Model saved.\n",
            "Epoch: 104 | Time: 42.94s | LR: 1.3e-04 | Train Loss: 0.7464 | Val Loss: 1.0904 | Val AUCPR: 0.3322 | Val F1: 0.2233\n",
            "Epoch 104: New best val AUCPR: 0.3322. Model saved.\n",
            "Epoch: 105 | Time: 42.56s | LR: 1.3e-04 | Train Loss: 0.7410 | Val Loss: 1.0830 | Val AUCPR: 0.3196 | Val F1: 0.2107\n",
            "Epoch: 106 | Time: 42.16s | LR: 1.3e-04 | Train Loss: 0.7489 | Val Loss: 1.0714 | Val AUCPR: 0.3061 | Val F1: 0.1582\n",
            "Epoch: 107 | Time: 42.76s | LR: 1.3e-04 | Train Loss: 0.7432 | Val Loss: 1.0559 | Val AUCPR: 0.3201 | Val F1: 0.1748\n",
            "Epoch: 108 | Time: 42.51s | LR: 1.3e-04 | Train Loss: 0.7418 | Val Loss: 1.1097 | Val AUCPR: 0.3319 | Val F1: 0.2377\n",
            "Epoch: 109 | Time: 42.63s | LR: 1.3e-04 | Train Loss: 0.7383 | Val Loss: 1.1187 | Val AUCPR: 0.3323 | Val F1: 0.2338\n",
            "Epoch 109: New best val AUCPR: 0.3323. Model saved.\n",
            "Epoch: 110 | Time: 42.14s | LR: 1.3e-04 | Train Loss: 0.7418 | Val Loss: 1.1111 | Val AUCPR: 0.3256 | Val F1: 0.2261\n",
            "Epoch: 111 | Time: 42.79s | LR: 1.3e-04 | Train Loss: 0.7453 | Val Loss: 1.0778 | Val AUCPR: 0.3220 | Val F1: 0.2088\n",
            "Epoch: 112 | Time: 42.18s | LR: 1.3e-04 | Train Loss: 0.7385 | Val Loss: 1.1280 | Val AUCPR: 0.3271 | Val F1: 0.2363\n",
            "Epoch: 113 | Time: 42.89s | LR: 1.3e-04 | Train Loss: 0.7391 | Val Loss: 1.0786 | Val AUCPR: 0.3245 | Val F1: 0.1985\n",
            "Epoch: 114 | Time: 42.74s | LR: 1.3e-04 | Train Loss: 0.7368 | Val Loss: 1.0741 | Val AUCPR: 0.3328 | Val F1: 0.1979\n",
            "Epoch 114: New best val AUCPR: 0.3328. Model saved.\n",
            "Epoch: 115 | Time: 42.65s | LR: 1.3e-04 | Train Loss: 0.7374 | Val Loss: 1.1248 | Val AUCPR: 0.3284 | Val F1: 0.2243\n",
            "Epoch: 116 | Time: 42.40s | LR: 1.3e-04 | Train Loss: 0.7309 | Val Loss: 1.0688 | Val AUCPR: 0.3293 | Val F1: 0.2107\n",
            "Epoch: 117 | Time: 42.55s | LR: 1.3e-04 | Train Loss: 0.7348 | Val Loss: 1.0727 | Val AUCPR: 0.3183 | Val F1: 0.1819\n",
            "Epoch: 118 | Time: 42.21s | LR: 1.3e-04 | Train Loss: 0.7336 | Val Loss: 1.1281 | Val AUCPR: 0.3273 | Val F1: 0.2388\n",
            "Epoch: 119 | Time: 42.47s | LR: 1.3e-04 | Train Loss: 0.7325 | Val Loss: 1.1306 | Val AUCPR: 0.3243 | Val F1: 0.2302\n",
            "Epoch: 120 | Time: 42.35s | LR: 1.3e-04 | Train Loss: 0.7279 | Val Loss: 1.1299 | Val AUCPR: 0.3289 | Val F1: 0.2351\n",
            "Epoch: 121 | Time: 42.47s | LR: 1.3e-04 | Train Loss: 0.7312 | Val Loss: 1.0788 | Val AUCPR: 0.3328 | Val F1: 0.1868\n",
            "Epoch 121: New best val AUCPR: 0.3328. Model saved.\n",
            "Epoch: 122 | Time: 42.22s | LR: 1.3e-04 | Train Loss: 0.7283 | Val Loss: 1.0747 | Val AUCPR: 0.3311 | Val F1: 0.2073\n",
            "Epoch: 123 | Time: 42.82s | LR: 1.3e-04 | Train Loss: 0.7315 | Val Loss: 1.0768 | Val AUCPR: 0.3204 | Val F1: 0.1988\n",
            "Epoch: 124 | Time: 42.54s | LR: 1.3e-04 | Train Loss: 0.7263 | Val Loss: 1.0813 | Val AUCPR: 0.3115 | Val F1: 0.1591\n",
            "Epoch: 125 | Time: 42.67s | LR: 1.3e-04 | Train Loss: 0.7316 | Val Loss: 1.0824 | Val AUCPR: 0.3084 | Val F1: 0.2109\n",
            "Epoch: 126 | Time: 42.98s | LR: 6.3e-05 | Train Loss: 0.7294 | Val Loss: 1.1016 | Val AUCPR: 0.3343 | Val F1: 0.2348\n",
            "Epoch 126: New best val AUCPR: 0.3343. Model saved.\n",
            "Epoch: 127 | Time: 42.48s | LR: 6.3e-05 | Train Loss: 0.7246 | Val Loss: 1.0742 | Val AUCPR: 0.3305 | Val F1: 0.2037\n",
            "Epoch: 128 | Time: 42.75s | LR: 6.3e-05 | Train Loss: 0.7258 | Val Loss: 1.0954 | Val AUCPR: 0.3328 | Val F1: 0.2235\n",
            "Epoch: 129 | Time: 42.21s | LR: 6.3e-05 | Train Loss: 0.7228 | Val Loss: 1.1034 | Val AUCPR: 0.3365 | Val F1: 0.2330\n",
            "Epoch 129: New best val AUCPR: 0.3365. Model saved.\n",
            "Epoch: 130 | Time: 41.96s | LR: 6.3e-05 | Train Loss: 0.7223 | Val Loss: 1.0942 | Val AUCPR: 0.3351 | Val F1: 0.2193\n",
            "Epoch: 131 | Time: 42.76s | LR: 6.3e-05 | Train Loss: 0.7187 | Val Loss: 1.1139 | Val AUCPR: 0.3313 | Val F1: 0.2292\n",
            "Epoch: 132 | Time: 43.44s | LR: 6.3e-05 | Train Loss: 0.7177 | Val Loss: 1.1216 | Val AUCPR: 0.3362 | Val F1: 0.2471\n",
            "Epoch: 133 | Time: 42.52s | LR: 6.3e-05 | Train Loss: 0.7223 | Val Loss: 1.1084 | Val AUCPR: 0.3339 | Val F1: 0.2234\n",
            "Epoch: 134 | Time: 42.47s | LR: 6.3e-05 | Train Loss: 0.7200 | Val Loss: 1.0773 | Val AUCPR: 0.3340 | Val F1: 0.2190\n",
            "Epoch: 135 | Time: 42.59s | LR: 6.3e-05 | Train Loss: 0.7171 | Val Loss: 1.1204 | Val AUCPR: 0.3355 | Val F1: 0.2248\n",
            "Epoch: 136 | Time: 42.32s | LR: 6.3e-05 | Train Loss: 0.7191 | Val Loss: 1.0996 | Val AUCPR: 0.3327 | Val F1: 0.2107\n",
            "Epoch: 137 | Time: 42.22s | LR: 6.3e-05 | Train Loss: 0.7189 | Val Loss: 1.1407 | Val AUCPR: 0.3351 | Val F1: 0.2368\n",
            "Epoch: 138 | Time: 42.36s | LR: 6.3e-05 | Train Loss: 0.7202 | Val Loss: 1.1799 | Val AUCPR: 0.3294 | Val F1: 0.2602\n",
            "Epoch: 139 | Time: 42.84s | LR: 6.3e-05 | Train Loss: 0.7226 | Val Loss: 1.0802 | Val AUCPR: 0.3341 | Val F1: 0.2107\n",
            "Epoch: 140 | Time: 42.67s | LR: 6.3e-05 | Train Loss: 0.7253 | Val Loss: 1.0901 | Val AUCPR: 0.3282 | Val F1: 0.2202\n",
            "Epoch: 141 | Time: 42.64s | LR: 3.1e-05 | Train Loss: 0.7157 | Val Loss: 1.1011 | Val AUCPR: 0.3365 | Val F1: 0.2224\n",
            "Epoch: 142 | Time: 42.57s | LR: 3.1e-05 | Train Loss: 0.7111 | Val Loss: 1.1137 | Val AUCPR: 0.3344 | Val F1: 0.2277\n",
            "Epoch: 143 | Time: 42.35s | LR: 3.1e-05 | Train Loss: 0.7134 | Val Loss: 1.1041 | Val AUCPR: 0.3328 | Val F1: 0.2229\n",
            "Epoch: 144 | Time: 42.82s | LR: 3.1e-05 | Train Loss: 0.7088 | Val Loss: 1.1281 | Val AUCPR: 0.3371 | Val F1: 0.2360\n",
            "Epoch 144: New best val AUCPR: 0.3371. Model saved.\n",
            "Epoch: 145 | Time: 43.40s | LR: 3.1e-05 | Train Loss: 0.7092 | Val Loss: 1.1252 | Val AUCPR: 0.3345 | Val F1: 0.2333\n",
            "Epoch: 146 | Time: 42.45s | LR: 3.1e-05 | Train Loss: 0.7180 | Val Loss: 1.0988 | Val AUCPR: 0.3362 | Val F1: 0.2191\n",
            "Epoch: 147 | Time: 43.15s | LR: 3.1e-05 | Train Loss: 0.7123 | Val Loss: 1.1323 | Val AUCPR: 0.3327 | Val F1: 0.2358\n",
            "Epoch: 148 | Time: 42.92s | LR: 3.1e-05 | Train Loss: 0.7122 | Val Loss: 1.1054 | Val AUCPR: 0.3326 | Val F1: 0.2190\n",
            "Epoch: 149 | Time: 42.72s | LR: 3.1e-05 | Train Loss: 0.7169 | Val Loss: 1.0992 | Val AUCPR: 0.3300 | Val F1: 0.2135\n",
            "Epoch: 150 | Time: 42.61s | LR: 3.1e-05 | Train Loss: 0.7148 | Val Loss: 1.1125 | Val AUCPR: 0.3361 | Val F1: 0.2289\n",
            "\n",
            "Loading best model from epoch 144 (Val AUCPR: 0.3371).\n",
            "\n",
            "--- Test Set Evaluation (Mini-Batching) ---\n",
            "Test Loss: 1.1327 | AUROC: 0.8489 | AUCPR: 0.4512\n",
            "Test F1: 0.2668 | Precision: 0.1647 | Recall: 0.7029\n",
            "Saved confusion matrix to test_confusion_matrix_batched_v2.png\n",
            "Total Estimated Financial Cost (Test): $93073\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 600x500 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QKWwV89Yrf8I"
      },
      "execution_count": 7,
      "outputs": []
    }
  ]
}